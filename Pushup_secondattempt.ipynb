{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushup form checker whoooo\n",
    "\n",
    "Hierin staat alles wat je nodig hebt om een ongeveer correcte push-up checker te hebben!\n",
    "Er zal nog veel getweaked moeten worden om het accurater te krijgen, en eventueel andere oefeningen toe te voegen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4d34d",
   "metadata": {},
   "source": [
    "# 0. Installs =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a3e928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (8.3.203)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (1.16.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (0.23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (1.33.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if needed to install packages\n",
    "%pip install ultralytics opencv-python numpy pandas scikit-learn matplotlib pyyaml tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6479a4",
   "metadata": {},
   "source": [
    "# 1. Imports & config setup\n",
    "Import alle benodigheden en defineert de paths naar data\n",
    "\n",
    "Checked ook voor mijn best weights bestand wat later van pas komt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29ce21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST_WEIGHTS: runs/pushup-cls42/weights/best.pt\n",
      "Exists? C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls42\\weights\\best.pt True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2, os, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATASET_DIR = \"C:/Data/hboict/Sem7-AIFS/Personal_Project\"\n",
    "RUNS_DIR = \"runs\"\n",
    "RUN_NAME = \"pushup-cls42\"  \n",
    "BEST_WEIGHTS = f\"{RUNS_DIR}/{RUN_NAME}/weights/best.pt\"  \n",
    "\n",
    "\n",
    "OUTPUT_FRAMES_DIR = \"data/frames\"  \n",
    "IMGSZ = 224\n",
    "\n",
    "print(\"BEST_WEIGHTS:\", BEST_WEIGHTS)\n",
    "print(\"Exists?\", Path(BEST_WEIGHTS).resolve(), Path(BEST_WEIGHTS).exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9991c",
   "metadata": {},
   "source": [
    "# 2. Random checks voor data hoeveelheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1946cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   split      class  count\n",
      "0  train    correct    295\n",
      "1  train  incorrect    326\n",
      "2    val    correct     38\n",
      "3    val  incorrect    139\n",
      "4   test    correct     66\n",
      "5   test  incorrect     47\n",
      "\n",
      "If any class has 0 images in *train*, fix your splits before training.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_images(root):\n",
    "    root = Path(root)\n",
    "    rows = []\n",
    "    for split in [\"train\",\"val\",\"test\"]:\n",
    "        for cls in [\"correct\",\"incorrect\"]:\n",
    "            n = len(list((root/split/cls).glob(\"*.jpg\")))\n",
    "            rows.append({\"split\":split,\"class\":cls,\"count\":n})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_counts = count_images(OUTPUT_FRAMES_DIR)\n",
    "try:\n",
    "    from caas_jupyter_tools import display_dataframe_to_user\n",
    "    display_dataframe_to_user(\"Dataset image counts\", df_counts)\n",
    "except Exception:\n",
    "    print(df_counts)\n",
    "\n",
    "print(\"\\nIf any class has 0 images in *train*, fix your splits before training.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f542a63",
   "metadata": {},
   "source": [
    "# 3. Classifier training\n",
    "Training YOLO on my defined image set/ how long, how fast etc.\n",
    "\n",
    "Uncomment als weer wilt trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf5511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.223 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.203  Python-3.13.7 torch-2.8.0+cpu CPU (13th Gen Intel Core i7-13700H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/frames, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-pose.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=pushup-cls426, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls426, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=pose, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Ultralytics 8.3.203  Python-3.13.7 torch-2.8.0+cpu CPU (13th Gen Intel Core i7-13700H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/frames, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-pose.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=pushup-cls426, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls426, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=pose, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'data/frames' error  [Errno 13] Permission denied: 'data/frames'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:638\u001b[39m, in \u001b[36mBaseTrainer.get_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.data.rsplit(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33myaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myml\u001b[39m\u001b[33m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.task \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m    633\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdetect\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    634\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msegment\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    635\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    636\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mobb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    637\u001b[39m }:\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m     data = \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33myaml_file\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\data\\utils.py:409\u001b[39m, in \u001b[36mcheck_det_dataset\u001b[39m\u001b[34m(dataset, autodownload)\u001b[39m\n\u001b[32m    408\u001b[39m extract_dir = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m zipfile.is_zipfile(file) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mis_tarfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    410\u001b[39m     new_dir = safe_download(file, \u001b[38;5;28mdir\u001b[39m=DATASETS_DIR, unzip=\u001b[38;5;28;01mTrue\u001b[39;00m, delete=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\tarfile.py:2962\u001b[39m, in \u001b[36mis_tarfile\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   2961\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2962\u001b[39m     t = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2963\u001b[39m t.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\tarfile.py:1878\u001b[39m, in \u001b[36mTarFile.open\u001b[39m\u001b[34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[39m\n\u001b[32m   1877\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1878\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1879\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ReadError, CompressionError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\tarfile.py:1946\u001b[39m, in \u001b[36mTarFile.gzopen\u001b[39m\u001b[34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[39m\n\u001b[32m   1945\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1946\u001b[39m     fileobj = \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\gzip.py:203\u001b[39m, in \u001b[36mGzipFile.__init__\u001b[39m\u001b[34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     fileobj = \u001b[38;5;28mself\u001b[39m.myfileobj = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'data/frames'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m      2\u001b[39m model = YOLO(\u001b[33m'\u001b[39m\u001b[33myolov8n-pose.pt\u001b[39m\u001b[33m'\u001b[39m)  \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUTPUT_FRAMES_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# training time\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMGSZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# input image size\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRUNS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRUN_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# run name\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr0\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.00001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# learning rate\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# batch sizes\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# data augmentation\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# early stopping\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\model.py:795\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.get(\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    793\u001b[39m     args[\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.ckpt_path\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer = \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrainer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args.get(\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\models\\yolo\\pose\\train.py:57\u001b[39m, in \u001b[36mPoseTrainer.__init__\u001b[39m\u001b[34m(self, cfg, overrides, _callbacks)\u001b[39m\n\u001b[32m     55\u001b[39m     overrides = {}\n\u001b[32m     56\u001b[39m overrides[\u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mpose\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args.device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.device.lower() == \u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     60\u001b[39m     LOGGER.warning(\n\u001b[32m     61\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mApple MPS known Pose bug. Recommend \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdevice=cpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for Pose models. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     62\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSee https://github.com/ultralytics/ultralytics/issues/4031.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     63\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:65\u001b[39m, in \u001b[36mDetectionTrainer.__init__\u001b[39m\u001b[34m(self, cfg, overrides, _callbacks)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg=DEFAULT_CFG, overrides: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, _callbacks=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     57\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m    Initialize a DetectionTrainer object for training YOLO object detection model training.\u001b[39;00m\n\u001b[32m     59\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m \u001b[33;03m        _callbacks (list, optional): List of callback functions to be executed during training.\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:158\u001b[39m, in \u001b[36mBaseTrainer.__init__\u001b[39m\u001b[34m(self, cfg, overrides, _callbacks)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.model = check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m.args.model)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28mself\u001b[39m.ema = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\models\\yolo\\pose\\train.py:112\u001b[39m, in \u001b[36mPoseTrainer.get_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    103\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    Retrieve the dataset and ensure it contains the required `kpt_shape` key.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    110\u001b[39m \u001b[33;03m        KeyError: If the `kpt_shape` key is not present in the dataset.\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     data = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mkpt_shape\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo `kpt_shape` in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.args.data\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. See https://docs.ultralytics.com/datasets/pose/\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\timle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:642\u001b[39m, in \u001b[36mBaseTrainer.get_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    640\u001b[39m             \u001b[38;5;28mself\u001b[39m.args.data = data[\u001b[33m\"\u001b[39m\u001b[33myaml_file\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m.args.data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m error ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.single_cls:\n\u001b[32m    644\u001b[39m     LOGGER.info(\u001b[33m\"\u001b[39m\u001b[33mOverriding class names with single class.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Dataset 'data/frames' error  [Errno 13] Permission denied: 'data/frames'"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n-pose.pt')  \n",
    "model.train(\n",
    "    data=OUTPUT_FRAMES_DIR,  \n",
    "    epochs=20,               # training time\n",
    "    imgsz=IMGSZ,             # input image size\n",
    "    project=RUNS_DIR,        \n",
    "    name=RUN_NAME,           # run name\n",
    "    lr0=0.00001,             # learning rate\n",
    "    batch=64,                # batch sizes\n",
    "    augment=True,            # data augmentation\n",
    "    patience=20              # early stopping\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9233a0",
   "metadata": {},
   "source": [
    "# 4. Evaluatie classifier + confusion matrix generation\n",
    "Na het trainen een korte evaluation met een confusion matrix generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda56498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping from model: {0: 'correct', 1: 'incorrect'}\n",
      "Ultralytics 8.3.203  Python-3.13.7 torch-2.8.0+cpu CPU (13th Gen Intel Core i7-13700H)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\train... found 621 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\val... found 177 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\test... found 113 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 31.45.0 MB/s, size: 14.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\test... 113 images, 0 corrupt: 100% ━━━━━━━━━━━━ 113/113 131.1Kit/s 0.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 8/8 7.4it/s 1.1s0.2s\n",
      "                   all      0.867          1\n",
      "Speed: 0.0ms preprocess, 6.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\classify\\val5\u001b[0m\n",
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001D265C53700>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.9336283206939697\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.8672566413879395, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9336283206939697}\n",
      "save_dir: WindowsPath('C:/Data/hboict/Sem7-AIFS/Personal_Project/runs/classify/val5')\n",
      "speed: {'preprocess': 0.001621238920277199, 'inference': 6.5821212385698695, 'loss': 5.575212180218865e-05, 'postprocess': 0.0002300881871343714}\n",
      "task: 'classify'\n",
      "top1: 0.8672566413879395\n",
      "top5: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct     1.0000    0.7727    0.8718        66\n",
      "   incorrect     0.7581    1.0000    0.8624        47\n",
      "\n",
      "    accuracy                         0.8673       113\n",
      "   macro avg     0.8790    0.8864    0.8671       113\n",
      "weighted avg     0.8994    0.8673    0.8679       113\n",
      "\n",
      "Saved confusion matrix to: runs\\pushup-cls4\\confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_weights = Path(BEST_WEIGHTS)\n",
    "if not best_weights.exists():\n",
    "    raise FileNotFoundError(f\"Best weights not found at {best_weights}. Train first or fix path.\")\n",
    "\n",
    "eval_model = YOLO(str(best_weights))\n",
    "print(\"Class mapping from model:\", eval_model.names)\n",
    "\n",
    "metrics = eval_model.val(data=str(OUTPUT_FRAMES_DIR), imgsz=IMGSZ, split=\"test\")\n",
    "print(metrics)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "class_names = [eval_model.names[i] for i in sorted(eval_model.names.keys())]\n",
    "name_to_index = {v:k for k,v in eval_model.names.items()}\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "test_dir = Path(OUTPUT_FRAMES_DIR) / \"test\"\n",
    "img_paths = []\n",
    "for cls in class_names:\n",
    "    cls_idx = name_to_index[cls]\n",
    "    for p in (test_dir / cls).glob(\"*.jpg\"):\n",
    "        img_paths.append((str(p), cls_idx))\n",
    "\n",
    "bs = 64\n",
    "for i in range(0, len(img_paths), bs):\n",
    "    batch = img_paths[i:i+bs]\n",
    "    imgs = [b[0] for b in batch]\n",
    "    gts = [b[1] for b in batch]\n",
    "    preds = eval_model(imgs, verbose=False)\n",
    "    for gt, pred in zip(gts, preds):\n",
    "        pred_cls = int(np.argmax(pred.probs.data))\n",
    "        y_true.append(gt)\n",
    "        y_pred.append(pred_cls)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[name_to_index[c] for c in class_names])\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "print(report)\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, out_path: Path):\n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    cm_normalized = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-9)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, f\"{cm[i, j]}\\n({cm_normalized[i, j]:.2f})\",\n",
    "                     horizontalalignment=\"center\", verticalalignment=\"center\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_confusion_matrix(cm, class_names, Path(RUNS_DIR) / RUN_NAME / \"confusion_matrix.png\")\n",
    "print(\"Saved confusion matrix to:\", Path(RUNS_DIR) / RUN_NAME / \"confusion_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c8d3e",
   "metadata": {},
   "source": [
    "# 5. Geometrie zooi en pose assesments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fc7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def angle(a, b, c):\n",
    "    # angle at b: a-b-c\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosang = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    cosang = np.clip(cosang, -1.0, 1.0)\n",
    "    return math.degrees(math.acos(cosang))\n",
    "\n",
    "def line_point_distance(p, a, b):\n",
    "    # distance from point p to line ab\n",
    "    p, a, b = np.array(p), np.array(a), np.array(b)\n",
    "    if np.allclose(a,b):\n",
    "        return np.linalg.norm(p-a)\n",
    "    return np.linalg.norm(np.cross(b-a, a-p)) / (np.linalg.norm(b-a) + 1e-6)\n",
    "\n",
    "# keypoint indices (YOLOv8-pose)\n",
    "KS = dict(nose=0, ls=5, rs=6, le=7, re=8, lw=9, rw=10, lh=11, rh=12, lk=13, rk=14, la=15, ra=16)\n",
    "\n",
    "def get_xy(kps, i):\n",
    "    # kps shape: (17,3) -> x,y,conf\n",
    "    return (float(kps[i,0]), float(kps[i,1]))\n",
    "\n",
    "def valid_triplet(kps, a,b,c, minconf=0.35):\n",
    "    return kps[a,2]>minconf and kps[b,2]>minconf and kps[c,2]>minconf\n",
    "\n",
    "def assess_form(kps, phase=\"bottom\"):\n",
    "    issues = []\n",
    "    # Depth\n",
    "    left_elbow = angle(get_xy(kps, KS['ls']), get_xy(kps, KS['le']), get_xy(kps, KS['lw'])) if valid_triplet(kps, KS['ls'], KS['le'], KS['lw']) else None\n",
    "    right_elbow = angle(get_xy(kps, KS['rs']), get_xy(kps, KS['re']), get_xy(kps, KS['rw'])) if valid_triplet(kps, KS['rs'], KS['re'], KS['rw']) else None\n",
    "    elbow_min = None\n",
    "    if left_elbow is not None and right_elbow is not None:\n",
    "        elbow_min = min(left_elbow, right_elbow)\n",
    "    elif left_elbow is not None:\n",
    "        elbow_min = left_elbow\n",
    "    elif right_elbow is not None:\n",
    "        elbow_min = right_elbow\n",
    "    # Depth check only at bottom phase\n",
    "    if phase == \"bottom\" and elbow_min is not None and elbow_min > 120:\n",
    "        issues.append(\"Depth too shallow (elbows not bent enough)\")\n",
    "\n",
    "    # Hip sag / pike\n",
    "    side = \"r\" if kps[KS['rs'],2] > kps[KS['ls'],2] else \"l\"\n",
    "    parts = ['rs','rh','ra'] if side == 'r' else ['ls','lh','la']\n",
    "    if kps[KS[parts[0]],2]>0.35 and kps[KS[parts[1]],2]>0.35 and kps[KS[parts[2]],2]>0.35:\n",
    "        shoulder = get_xy(kps, KS[parts[0]])\n",
    "        hip = get_xy(kps, KS[parts[1]])\n",
    "        ankle = get_xy(kps, KS[parts[2]])\n",
    "        sag = line_point_distance(hip, shoulder, ankle)\n",
    "        norm = np.linalg.norm(np.array(shoulder) - np.array(ankle)) + 1e-6\n",
    "        if sag / norm > 0.12:  # relaxed\n",
    "            issues.append(\"Hips sagging (keep core tight)\")\n",
    "\n",
    "    # Elbow flaring (only at bottom)\n",
    "    if kps[KS['rs'],2]>0.35 and kps[KS['rh'],2]>0.35 and kps[KS['re'],2]>0.35:\n",
    "        rs, rh, re = get_xy(kps, KS['rs']), get_xy(kps, KS['rh']), get_xy(kps, KS['re'])\n",
    "        torso_vec = np.array(rh) - np.array(rs)\n",
    "        arm_vec = np.array(re) - np.array(rs)\n",
    "        cosang = abs(np.dot(torso_vec, arm_vec)) / (np.linalg.norm(torso_vec)*np.linalg.norm(arm_vec)+1e-6)\n",
    "        flare_angle = math.degrees(math.acos(np.clip(cosang, -1, 1)))\n",
    "        if flare_angle > 70:  # slightly relaxed position instead of 45°\n",
    "            issues.append(\"Elbows flaring out (keep ~45° from torso)\")\n",
    "\n",
    "    return issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35b61a",
   "metadata": {},
   "source": [
    "# 6. Pose-based rep count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PoseRepCounter:\n",
    "    def __init__(self, pose_model, eval_model, frames_for_classify=7, vote_strategy=\"majority\"):\n",
    "        self.model = pose_model\n",
    "        self.eval_model = eval_model\n",
    "        self.prev_y = deque(maxlen=5)\n",
    "        self.state = \"up\"\n",
    "        self.last_bottom_time = None\n",
    "        self.reps = 0\n",
    "        self.rep_events = []  # list of dicts with rep info\n",
    "        self.frames_buffer = deque(maxlen=frames_for_classify)\n",
    "        self.frames_for_classify = frames_for_classify\n",
    "        self.vote_strategy = vote_strategy\n",
    "\n",
    "    def classify_buffer(self):\n",
    "        if len(self.frames_buffer) == 0:\n",
    "            return None, None\n",
    "        preds = self.eval_model(list(self.frames_buffer), verbose=False)\n",
    "        top1 = [int(p.probs.top1) for p in preds]\n",
    "        if self.vote_strategy == \"majority\":\n",
    "            final_pred = max(set(top1), key=top1.count)\n",
    "        else:\n",
    "            final_pred = top1[-1]\n",
    "        label = self.eval_model.names[final_pred]\n",
    "        confs = [float(p.probs.top1conf) for p in preds]\n",
    "        return label, float(np.mean(confs))\n",
    "\n",
    "    def update(self, frame):\n",
    "        self.frames_buffer.append(frame.copy())\n",
    "        res = self.model(frame, verbose=False)[0]\n",
    "        kps_best = None\n",
    "\n",
    "        if res.keypoints is not None and len(res.keypoints) > 0:\n",
    "            # Select best keypoint set (highest avg confidence)\n",
    "            best_i = 0\n",
    "            best_score = -1\n",
    "            for i, kp in enumerate(res.keypoints):\n",
    "                conf = float(kp.conf.mean())\n",
    "                if conf > best_score:\n",
    "                    best_score = conf\n",
    "                    best_i = i\n",
    "            kps = res.keypoints[best_i].data[0].cpu().numpy()  # (17,3)\n",
    "            kps_best = kps\n",
    "\n",
    "            # Compute mean y of shoulders and hips\n",
    "            y_points = []\n",
    "            for idx in [KS['ls'], KS['rs'], KS['lh'], KS['rh']]:\n",
    "                if kps[idx,2] > 0.35:\n",
    "                    y_points.append(kps[idx,1])\n",
    "            if len(y_points)>=2:\n",
    "                y_mean = float(np.mean(y_points))\n",
    "                self.prev_y.append(y_mean)\n",
    "\n",
    "            if len(self.prev_y) == self.prev_y.maxlen:\n",
    "                dy = self.prev_y[-1] - self.prev_y[0]\n",
    "                # simple hysteresis on y to detect down/up\n",
    "                if self.state == \"up\" and dy > 8:\n",
    "                    self.state = \"down\"\n",
    "                elif self.state == \"down\" and dy < -8:\n",
    "                    self.state = \"up\"\n",
    "                    # Completed a rep\n",
    "                    self.reps += 1\n",
    "                    # Classify the buffered frames around bottom position\n",
    "                    feedback_label, avg_conf = self.classify_buffer()\n",
    "                    issues = assess_form(kps, phase=\"bottom\")\n",
    "                    event = {\n",
    "                        \"rep\": self.reps,\n",
    "                        \"time\": time.time(),\n",
    "                        \"feedback\": feedback_label,\n",
    "                        \"issues\": issues,\n",
    "                        \"kps_conf\": float(np.mean(kps[:,2])),\n",
    "                        \"clf_conf\": avg_conf,\n",
    "                    }\n",
    "                    self.rep_events.append(event)\n",
    "                    return True, event, kps_best\n",
    "\n",
    "        return False, None, kps_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb02e96",
   "metadata": {},
   "source": [
    "# 6.5 teller voor hoeveelheid correct/incorrect frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff09ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 295\n",
      "incorrect 326\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "for cls in [\"correct\",\"incorrect\"]:\n",
    "    n = len(list((Path(\"data/frames/train\")/cls).glob(\"*.jpg\")))\n",
    "    print(cls, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30ed67",
   "metadata": {},
   "source": [
    "# 7. Quick check for my own sanity\n",
    "Checks whether my trained images are in the correct folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f5d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model names: {0: 'correct', 1: 'incorrect'}\n",
      "Copy of push up 46_f00003.jpg {0: 'correct', 1: 'incorrect'} 0 correct 0.9995589852333069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = YOLO(BEST_WEIGHTS)\n",
    "print(\"Model names:\", model.names)\n",
    "\n",
    "correct_list = list((Path(OUTPUT_FRAMES_DIR)/\"test\"/\"correct\").glob(\"*.jpg\"))\n",
    "incorrect_list = list((Path(OUTPUT_FRAMES_DIR)/\"test\"/\"incorrect\").glob(\"*.jpg\"))\n",
    "if correct_list and incorrect_list:\n",
    "    import random\n",
    "    for img_path in [random.choice(correct_list), random.choice(incorrect_list)]:\n",
    "        r = model(str(img_path), verbose=False)[0]\n",
    "    print(\n",
    "        img_path.name,\n",
    "        r.names,\n",
    "        int(r.probs.top1),\n",
    "        r.names[int(r.probs.top1)],\n",
    "        float(r.probs.top1conf)\n",
    "    )\n",
    "else:\n",
    "    print(\"No test images found for quick check.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb68164",
   "metadata": {},
   "source": [
    "## 7.5\n",
    "Quick check for data accuracy and estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88b27a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'correct', 1: 'incorrect'}\n",
      "Copy of push up 132_f00004.jpg: expected=correct  predicted=correct  conf=1.00\n",
      "Copy of push up 46_f00004.jpg: expected=incorrect  predicted=correct  conf=0.99\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "model = YOLO(\"runs/pushup-cls42/weights/best.pt\")\n",
    "print(model.names)\n",
    "\n",
    "for cls in [\"correct\",\"incorrect\"]:\n",
    "    p = random.choice(list((Path(\"data/frames/test\")/cls).glob(\"*.jpg\")))\n",
    "    r = model(str(p), verbose=False)[0]\n",
    "    pred = model.names[int(r.probs.top1)]\n",
    "    conf = float(r.probs.top1conf)\n",
    "    print(f\"{p.name}: expected={cls}  predicted={pred}  conf={conf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5757989b",
   "metadata": {},
   "source": [
    "# 8. Live Push-up Form Test (Webcam) \n",
    "Execute the program and run the yolo webcam + rep counter. Feedback is provided shortly on screen, or in the terminal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa169433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier loaded: {0: 'correct', 1: 'incorrect'}\n",
      "Press 'q' to quit the live test.\n",
      "Rep 1: INCORRECT | Good form!\n",
      "Rep 2: INCORRECT | Good form!\n",
      "Rep 3: INCORRECT | Good form!\n",
      "Rep 4: INCORRECT | Good form!\n",
      "Rep 5: INCORRECT | Good form!\n",
      "Rep 6: INCORRECT | Good form!\n",
      "Rep 7: INCORRECT | Good form!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timle\\AppData\\Local\\Temp\\ipykernel_10160\\1309306314.py:16: DeprecationWarning: Arrays of 2-dimensional vectors are deprecated. Use arrays of 3-dimensional vectors instead. (deprecated in NumPy 2.0)\n",
      "  return np.linalg.norm(np.cross(b-a, a-p)) / (np.linalg.norm(b-a) + 1e-6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep 8: INCORRECT | Depth too shallow (elbows not bent enough), Hips sagging (keep core tight)\n",
      "Rep 9: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 10: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 11: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 12: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 13: INCORRECT | Depth too shallow (elbows not bent enough), Hips sagging (keep core tight)\n",
      "Rep 14: INCORRECT | Good form!\n",
      "Rep 15: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 16: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 17: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 18: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 19: CORRECT | Good form!\n",
      "Rep 20: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 21: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 22: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 23: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 24: INCORRECT | Depth too shallow (elbows not bent enough)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2, time\n",
    "from pathlib import Path\n",
    "\n",
    "# load models\n",
    "RUNS_DIR = \"runs\"\n",
    "RUN_NAME = \"pushup-cls42\"  # dit updaten naar gewenste run\n",
    "BEST_WEIGHTS = f\"{RUNS_DIR}/{RUN_NAME}/weights/best.pt\"\n",
    "\n",
    "pose_model = YOLO(\"yolov8n-pose.pt\")   \n",
    "clf_model = YOLO(BEST_WEIGHTS)         \n",
    "print(\"Classifier loaded:\", clf_model.names)\n",
    "\n",
    "# rep counter init\n",
    "rep_counter = PoseRepCounter(\n",
    "    pose_model=pose_model,\n",
    "    eval_model=clf_model,\n",
    "    frames_for_classify=7,\n",
    "    vote_strategy=\"majority\"\n",
    ")\n",
    "\n",
    "# webcam setup\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open webcam\")\n",
    "\n",
    "print(\"Press 'q' to quit the live test.\")\n",
    "\n",
    "# feedback timer\n",
    "feedback_text = \"\"\n",
    "feedback_end_time = 0\n",
    "\n",
    "# optional video recorder\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter(\"pushup_session.mp4\", fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # mirror image\n",
    "    counted, event, kps = rep_counter.update(frame)\n",
    "\n",
    "    # rep counter on screen\n",
    "    text = f\"Reps: {rep_counter.reps}\"\n",
    "    cv2.putText(frame, text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 2)\n",
    "\n",
    "    # feedback on screen\n",
    "    if counted and event:\n",
    "        feedback = event.get(\"feedback\", \"unknown\")\n",
    "        issues = \", \".join(event.get(\"issues\", [])) or \"Good form!\"\n",
    "        print(f\"Rep {event['rep']}: {feedback.upper()} | {issues}\")\n",
    "        feedback_text = f\"{feedback.upper()} - {issues}\"\n",
    "        feedback_end_time = time.time() + 3  # Show for 3 seconds\n",
    "    \n",
    "    # display feedback if timer hasn't expired\n",
    "    if time.time() < feedback_end_time:\n",
    "        cv2.putText(frame, feedback_text, (10, 80),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2)\n",
    "\n",
    "    # Display window\n",
    "    cv2.imshow(\"Push-up Form Tracker\", frame)\n",
    "\n",
    "    # optional write to output video\n",
    "    # out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# out.release()"
   ]
  }
 ],
 "metadata": {
  "created": "2025-11-01T16:22:55.964391Z",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
