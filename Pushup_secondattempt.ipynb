{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pushup form checker whoooo\n",
    "\n",
    "Hierin staat alles wat je nodig hebt om een ongeveer correcte push-up checker te hebben!\n",
    "Er zal nog veel getweaked moeten worden om het accurater te krijgen, en eventueel andere oefeningen toe te voegen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4d34d",
   "metadata": {},
   "source": [
    "# 0. Installs =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3e928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (8.3.203)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (1.16.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (0.23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (1.33.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Uncomment if needed to install packages\n",
    "# %pip install ultralytics opencv-python numpy pandas scikit-learn matplotlib pyyaml tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6479a4",
   "metadata": {},
   "source": [
    "# 1. Imports & config setup\n",
    "Import alle benodigheden en defineert de paths naar data\n",
    "\n",
    "Checked ook voor mijn best weights bestand wat later van pas komt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ce21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST_WEIGHTS: runs/pushup-cls42/weights/best.pt\n",
      "Exists? C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls42\\weights\\best.pt True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2, os, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATASET_DIR = \"C:/Data/hboict/Sem7-AIFS/Personal_Project\"\n",
    "RUNS_DIR = \"runs\"\n",
    "RUN_NAME = \"pushup-cls42\"  \n",
    "BEST_WEIGHTS = f\"{RUNS_DIR}/{RUN_NAME}/weights/best.pt\"  \n",
    "\n",
    "\n",
    "OUTPUT_FRAMES_DIR = \"data/frames\"  \n",
    "IMGSZ = 224\n",
    "\n",
    "print(\"BEST_WEIGHTS:\", BEST_WEIGHTS)\n",
    "print(\"Exists?\", Path(BEST_WEIGHTS).resolve(), Path(BEST_WEIGHTS).exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9991c",
   "metadata": {},
   "source": [
    "# 2. Random checks voor data hoeveelheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   split      class  count\n",
      "0  train    correct    295\n",
      "1  train  incorrect    326\n",
      "2    val    correct     38\n",
      "3    val  incorrect    139\n",
      "4   test    correct     66\n",
      "5   test  incorrect     47\n",
      "\n",
      "If any class has 0 images in *train*, fix your splits before training.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_images(root):\n",
    "    root = Path(root)\n",
    "    rows = []\n",
    "    for split in [\"train\",\"val\",\"test\"]:\n",
    "        for cls in [\"correct\",\"incorrect\"]:\n",
    "            n = len(list((root/split/cls).glob(\"*.jpg\")))\n",
    "            rows.append({\"split\":split,\"class\":cls,\"count\":n})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_counts = count_images(OUTPUT_FRAMES_DIR)\n",
    "try:\n",
    "    from caas_jupyter_tools import display_dataframe_to_user\n",
    "    display_dataframe_to_user(\"Dataset image counts\", df_counts)\n",
    "except Exception:\n",
    "    print(df_counts)\n",
    "\n",
    "print(\"\\nIf any class has 0 images in *train*, fix your splits before training.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f542a63",
   "metadata": {},
   "source": [
    "# 3. Classifier training\n",
    "Training YOLO on my defined image set/ how long, how fast etc.\n",
    "\n",
    "Uncomment als weer wilt trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-cls.pt to 'yolov8s-cls.pt': 100% ━━━━━━━━━━━━ 12.3MB 48.3MB/s 0.3s.2s<0.2s\n",
      "New https://pypi.org/project/ultralytics/8.3.223 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.203  Python-3.13.7 torch-2.8.0+cpu CPU (13th Gen Intel Core i7-13700H)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/frames, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=pushup-cls42, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls42, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\train... found 621 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\val... found 177 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\test... found 113 images in 2 classes  \n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    660482  ultralytics.nn.modules.head.Classify         [512, 2]                      \n",
      "YOLOv8s-cls summary: 56 layers, 5,083,298 parameters, 5,083,298 gradients, 12.6 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 23.54.7 MB/s, size: 14.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\train... 621 images, 0 corrupt: 100% ━━━━━━━━━━━━ 621/621 2.0Kit/s 0.3s0.0ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 20.93.6 MB/s, size: 11.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\val... 177 images, 0 corrupt: 100% ━━━━━━━━━━━━ 177/177 1.8Kit/s 0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls42\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      1/100         0G     0.6608         45        224: 100% ━━━━━━━━━━━━ 10/10 0.5it/s 21.1s.9ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.1s\n",
      "                   all      0.463          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      2/100         0G     0.4148         45        224: 100% ━━━━━━━━━━━━ 10/10 0.5it/s 19.5s.8ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.7s4.2s\n",
      "                   all      0.542          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      3/100         0G     0.2527         45        224: 100% ━━━━━━━━━━━━ 10/10 0.3it/s 35.7s.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.3it/s 6.0s14.2s\n",
      "                   all      0.633          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      4/100         0G      0.151         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:02.1s8s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.3it/s 6.1s13.8s\n",
      "                   all      0.599          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      5/100         0G      0.109         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:02.8s4s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.3it/s 5.8s12.9s\n",
      "                   all      0.582          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      6/100         0G     0.1222         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:00.8s8s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.6s12.5s\n",
      "                   all      0.661          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      7/100         0G     0.1157         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:01.5s5s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.0s11.7s\n",
      "                   all      0.559          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      8/100         0G    0.09175         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 53.7s.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.4s12.5s\n",
      "                   all      0.458          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      9/100         0G    0.08607         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 54.3s.1ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.4s\n",
      "                   all       0.61          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     10/100         0G    0.06212         45        224: 100% ━━━━━━━━━━━━ 10/10 0.5it/s 19.5s.9ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.2s\n",
      "                   all       0.61          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     11/100         0G    0.08244         45        224: 100% ━━━━━━━━━━━━ 10/10 0.3it/s 30.0s.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.7it/s 2.9s6.6s\n",
      "                   all      0.582          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     12/100         0G     0.1129         45        224: 100% ━━━━━━━━━━━━ 10/10 0.3it/s 34.0s.7ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.5s12.4s\n",
      "                   all      0.571          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     13/100         0G     0.1037         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 56.3s.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.5s12.4s\n",
      "                   all      0.593          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     14/100         0G     0.1398         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:01.7s2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.3it/s 5.9s13.7s\n",
      "                   all      0.559          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     15/100         0G    0.07934         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:02.7s9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.3it/s 5.9s13.6s\n",
      "                   all      0.644          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     16/100         0G     0.1098         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:02.1s5s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.7s13.1s\n",
      "                   all      0.638          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     17/100         0G     0.1059         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:03.9s3s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.4s12.3s\n",
      "                   all      0.599          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     18/100         0G    0.07031         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 59.1s.9ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.3it/s 6.2s14.0s\n",
      "                   all      0.672          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     19/100         0G    0.05605         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:05.2s9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.3it/s 6.0s13.6s\n",
      "                   all      0.684          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     20/100         0G    0.08559         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:02.5s8s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.3s11.5s\n",
      "                   all      0.638          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     21/100         0G    0.07645         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 40.3s.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.6it/s 3.3s7.8s\n",
      "                   all      0.599          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     22/100         0G    0.05238         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 46.1s.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.2s12.0s\n",
      "                   all      0.695          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     23/100         0G    0.03884         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 59.2s.8ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.3it/s 5.9s13.2s\n",
      "                   all      0.621          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     24/100         0G     0.0326         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:03.0s3s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.7s13.2s\n",
      "                   all       0.61          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     25/100         0G    0.03707         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 1:02.8s3s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.4s12.4s\n",
      "                   all      0.638          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     26/100         0G    0.04257         45        224: 100% ━━━━━━━━━━━━ 10/10 0.3it/s 31.4s.9ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s4.0s\n",
      "                   all      0.684          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     27/100         0G     0.0529         45        224: 100% ━━━━━━━━━━━━ 10/10 0.5it/s 18.9s.8ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.3s\n",
      "                   all      0.599          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     28/100         0G    0.06481         45        224: 100% ━━━━━━━━━━━━ 10/10 0.4it/s 27.5s.9ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.4s\n",
      "                   all      0.644          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     29/100         0G     0.0658         45        224: 100% ━━━━━━━━━━━━ 10/10 0.4it/s 25.8s.9ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.6it/s 3.1s7.0s\n",
      "                   all      0.565          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     30/100         0G    0.04923         45        224: 100% ━━━━━━━━━━━━ 10/10 0.3it/s 34.9s.5ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.7it/s 2.9s6.6s\n",
      "                   all      0.559          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     31/100         0G    0.05709         45        224: 100% ━━━━━━━━━━━━ 10/10 0.3it/s 29.7s.0ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.6it/s 3.2s7.5s\n",
      "                   all      0.571          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     32/100         0G    0.04406         45        224: 100% ━━━━━━━━━━━━ 10/10 0.3it/s 32.5s.2ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.7it/s 2.7s5.5s\n",
      "                   all      0.605          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     33/100         0G    0.02475         45        224: 100% ━━━━━━━━━━━━ 10/10 0.3it/s 34.8s.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.6it/s 3.1s6.9s\n",
      "                   all      0.565          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     34/100         0G    0.02167         45        224: 100% ━━━━━━━━━━━━ 10/10 0.3it/s 36.6s.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.6it/s 3.1s6.8s\n",
      "                   all      0.565          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     35/100         0G    0.03469         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 42.2s.6ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 5.2s11.5s\n",
      "                   all      0.616          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     36/100         0G     0.0194         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 54.0s.0ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 4.9s11.5s\n",
      "                   all       0.61          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     37/100         0G    0.01855         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 50.9s.8ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 4.6s10.8s\n",
      "                   all      0.605          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     38/100         0G    0.03818         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 54.3s.4ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.4it/s 4.8s10.9s\n",
      "                   all      0.621          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     39/100         0G    0.02808         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 54.2s.1ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 0.5it/s 4.4s10.3s\n",
      "                   all      0.678          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     40/100         0G    0.03445         45        224: 100% ━━━━━━━━━━━━ 10/10 0.2it/s 49.1s.8ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s4.1s\n",
      "                   all      0.638          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     41/100         0G    0.01539         45        224: 100% ━━━━━━━━━━━━ 10/10 0.5it/s 18.3s.8ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.5s\n",
      "                   all      0.633          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K     42/100         0G    0.02875         45        224: 100% ━━━━━━━━━━━━ 10/10 0.5it/s 18.7s.8ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s4.1s\n",
      "                   all       0.65          1\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 22, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "42 epochs completed in 0.580 hours.\n",
      "Optimizer stripped from C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls42\\weights\\last.pt, 10.3MB\n",
      "Optimizer stripped from C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls42\\weights\\best.pt, 10.3MB\n",
      "\n",
      "Validating C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls42\\weights\\best.pt...\n",
      "Ultralytics 8.3.203  Python-3.13.7 torch-2.8.0+cpu CPU (13th Gen Intel Core i7-13700H)\n",
      "YOLOv8s-cls summary (fused): 30 layers, 5,077,762 parameters, 0 gradients, 12.4 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\train... found 621 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\val... found 177 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\test... found 113 images in 2 classes  \n",
      "WARNING ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n",
      "\u001b[K               classes   top1_acc   top5_acc: 50% ━━━━━━────── 1/2 0.3it/s 1.1s<3.6sWARNING ClassificationModel does not support 'augment=True' prediction. Reverting to single-scale prediction.\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s\n",
      "                   all      0.695          1\n",
      "Speed: 0.0ms preprocess, 7.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\pushup-cls42\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001D2619E8A60>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.847457617521286\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.694915235042572, 'metrics/accuracy_top5': 1.0, 'fitness': 0.847457617521286}\n",
       "save_dir: WindowsPath('C:/Data/hboict/Sem7-AIFS/Personal_Project/runs/pushup-cls42')\n",
       "speed: {'preprocess': 0.00014463271866789308, 'inference': 7.015820338928777, 'loss': 6.214572158826274e-06, 'postprocess': 2.485878192056707e-05}\n",
       "task: 'classify'\n",
       "top1: 0.694915235042572\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from ultralytics import YOLO\n",
    "# model = YOLO('yolov8s-cls.pt')  \n",
    "# model.train(\n",
    "#     data=OUTPUT_FRAMES_DIR,  \n",
    "#     epochs=100,              # training time\n",
    "#     imgsz=IMGSZ,             # input image size\n",
    "#     project=RUNS_DIR,        \n",
    "#     name=RUN_NAME,           # run name\n",
    "#     lr0=0.001,               # learning rate\n",
    "#     batch=64,                # batch sizes\n",
    "#     augment=True,            # data augmentation\n",
    "#     patience=20              # early stopping\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9233a0",
   "metadata": {},
   "source": [
    "# 4. Evaluatie classifier + confusion matrix generation\n",
    "Na het trainen een korte evaluation met een confusion matrix generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda56498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping from model: {0: 'correct', 1: 'incorrect'}\n",
      "Ultralytics 8.3.203  Python-3.13.7 torch-2.8.0+cpu CPU (13th Gen Intel Core i7-13700H)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\train... found 621 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\val... found 177 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\test... found 113 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 31.45.0 MB/s, size: 14.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtest: \u001b[0mScanning C:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\data\\frames\\test... 113 images, 0 corrupt: 100% ━━━━━━━━━━━━ 113/113 131.1Kit/s 0.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 8/8 7.4it/s 1.1s0.2s\n",
      "                   all      0.867          1\n",
      "Speed: 0.0ms preprocess, 6.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Data\\hboict\\Sem7-AIFS\\Personal_Project\\runs\\classify\\val5\u001b[0m\n",
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001D265C53700>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.9336283206939697\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.8672566413879395, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9336283206939697}\n",
      "save_dir: WindowsPath('C:/Data/hboict/Sem7-AIFS/Personal_Project/runs/classify/val5')\n",
      "speed: {'preprocess': 0.001621238920277199, 'inference': 6.5821212385698695, 'loss': 5.575212180218865e-05, 'postprocess': 0.0002300881871343714}\n",
      "task: 'classify'\n",
      "top1: 0.8672566413879395\n",
      "top5: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct     1.0000    0.7727    0.8718        66\n",
      "   incorrect     0.7581    1.0000    0.8624        47\n",
      "\n",
      "    accuracy                         0.8673       113\n",
      "   macro avg     0.8790    0.8864    0.8671       113\n",
      "weighted avg     0.8994    0.8673    0.8679       113\n",
      "\n",
      "Saved confusion matrix to: runs\\pushup-cls4\\confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_weights = Path(BEST_WEIGHTS)\n",
    "if not best_weights.exists():\n",
    "    raise FileNotFoundError(f\"Best weights not found at {best_weights}. Train first or fix path.\")\n",
    "\n",
    "eval_model = YOLO(str(best_weights))\n",
    "print(\"Class mapping from model:\", eval_model.names)\n",
    "\n",
    "metrics = eval_model.val(data=str(OUTPUT_FRAMES_DIR), imgsz=IMGSZ, split=\"test\")\n",
    "print(metrics)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "class_names = [eval_model.names[i] for i in sorted(eval_model.names.keys())]\n",
    "name_to_index = {v:k for k,v in eval_model.names.items()}\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "test_dir = Path(OUTPUT_FRAMES_DIR) / \"test\"\n",
    "img_paths = []\n",
    "for cls in class_names:\n",
    "    cls_idx = name_to_index[cls]\n",
    "    for p in (test_dir / cls).glob(\"*.jpg\"):\n",
    "        img_paths.append((str(p), cls_idx))\n",
    "\n",
    "bs = 64\n",
    "for i in range(0, len(img_paths), bs):\n",
    "    batch = img_paths[i:i+bs]\n",
    "    imgs = [b[0] for b in batch]\n",
    "    gts = [b[1] for b in batch]\n",
    "    preds = eval_model(imgs, verbose=False)\n",
    "    for gt, pred in zip(gts, preds):\n",
    "        pred_cls = int(np.argmax(pred.probs.data))\n",
    "        y_true.append(gt)\n",
    "        y_pred.append(pred_cls)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[name_to_index[c] for c in class_names])\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "print(report)\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, out_path: Path):\n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    cm_normalized = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-9)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, f\"{cm[i, j]}\\n({cm_normalized[i, j]:.2f})\",\n",
    "                     horizontalalignment=\"center\", verticalalignment=\"center\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_confusion_matrix(cm, class_names, Path(RUNS_DIR) / RUN_NAME / \"confusion_matrix.png\")\n",
    "print(\"Saved confusion matrix to:\", Path(RUNS_DIR) / RUN_NAME / \"confusion_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c8d3e",
   "metadata": {},
   "source": [
    "# 5. Geometrie zooi en pose assesments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fc7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def angle(a, b, c):\n",
    "    # angle at b: a-b-c\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosang = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    cosang = np.clip(cosang, -1.0, 1.0)\n",
    "    return math.degrees(math.acos(cosang))\n",
    "\n",
    "def line_point_distance(p, a, b):\n",
    "    # distance from point p to line ab\n",
    "    p, a, b = np.array(p), np.array(a), np.array(b)\n",
    "    if np.allclose(a,b):\n",
    "        return np.linalg.norm(p-a)\n",
    "    return np.linalg.norm(np.cross(b-a, a-p)) / (np.linalg.norm(b-a) + 1e-6)\n",
    "\n",
    "# keypoint indices (YOLOv8-pose)\n",
    "KS = dict(nose=0, ls=5, rs=6, le=7, re=8, lw=9, rw=10, lh=11, rh=12, lk=13, rk=14, la=15, ra=16)\n",
    "\n",
    "def get_xy(kps, i):\n",
    "    # kps shape: (17,3) -> x,y,conf\n",
    "    return (float(kps[i,0]), float(kps[i,1]))\n",
    "\n",
    "def valid_triplet(kps, a,b,c, minconf=0.35):\n",
    "    return kps[a,2]>minconf and kps[b,2]>minconf and kps[c,2]>minconf\n",
    "\n",
    "def assess_form(kps, phase=\"bottom\"):\n",
    "    issues = []\n",
    "    # Depth\n",
    "    left_elbow = angle(get_xy(kps, KS['ls']), get_xy(kps, KS['le']), get_xy(kps, KS['lw'])) if valid_triplet(kps, KS['ls'], KS['le'], KS['lw']) else None\n",
    "    right_elbow = angle(get_xy(kps, KS['rs']), get_xy(kps, KS['re']), get_xy(kps, KS['rw'])) if valid_triplet(kps, KS['rs'], KS['re'], KS['rw']) else None\n",
    "    elbow_min = None\n",
    "    if left_elbow is not None and right_elbow is not None:\n",
    "        elbow_min = min(left_elbow, right_elbow)\n",
    "    elif left_elbow is not None:\n",
    "        elbow_min = left_elbow\n",
    "    elif right_elbow is not None:\n",
    "        elbow_min = right_elbow\n",
    "    # Depth check only at bottom phase\n",
    "    if phase == \"bottom\" and elbow_min is not None and elbow_min > 120:\n",
    "        issues.append(\"Depth too shallow (elbows not bent enough)\")\n",
    "\n",
    "    # Hip sag / pike\n",
    "    side = \"r\" if kps[KS['rs'],2] > kps[KS['ls'],2] else \"l\"\n",
    "    parts = ['rs','rh','ra'] if side == 'r' else ['ls','lh','la']\n",
    "    if kps[KS[parts[0]],2]>0.35 and kps[KS[parts[1]],2]>0.35 and kps[KS[parts[2]],2]>0.35:\n",
    "        shoulder = get_xy(kps, KS[parts[0]])\n",
    "        hip = get_xy(kps, KS[parts[1]])\n",
    "        ankle = get_xy(kps, KS[parts[2]])\n",
    "        sag = line_point_distance(hip, shoulder, ankle)\n",
    "        norm = np.linalg.norm(np.array(shoulder) - np.array(ankle)) + 1e-6\n",
    "        if sag / norm > 0.12:  # relaxed\n",
    "            issues.append(\"Hips sagging (keep core tight)\")\n",
    "\n",
    "    # Elbow flaring (only at bottom)\n",
    "    if kps[KS['rs'],2]>0.35 and kps[KS['rh'],2]>0.35 and kps[KS['re'],2]>0.35:\n",
    "        rs, rh, re = get_xy(kps, KS['rs']), get_xy(kps, KS['rh']), get_xy(kps, KS['re'])\n",
    "        torso_vec = np.array(rh) - np.array(rs)\n",
    "        arm_vec = np.array(re) - np.array(rs)\n",
    "        cosang = abs(np.dot(torso_vec, arm_vec)) / (np.linalg.norm(torso_vec)*np.linalg.norm(arm_vec)+1e-6)\n",
    "        flare_angle = math.degrees(math.acos(np.clip(cosang, -1, 1)))\n",
    "        if flare_angle > 70:  # slightly relaxed position instead of 45°\n",
    "            issues.append(\"Elbows flaring out (keep ~45° from torso)\")\n",
    "\n",
    "    return issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35b61a",
   "metadata": {},
   "source": [
    "# 6. Pose-based rep count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PoseRepCounter:\n",
    "    def __init__(self, pose_model, eval_model, frames_for_classify=7, vote_strategy=\"majority\"):\n",
    "        self.model = pose_model\n",
    "        self.eval_model = eval_model\n",
    "        self.prev_y = deque(maxlen=5)\n",
    "        self.state = \"up\"\n",
    "        self.last_bottom_time = None\n",
    "        self.reps = 0\n",
    "        self.rep_events = []  # list of dicts with rep info\n",
    "        self.frames_buffer = deque(maxlen=frames_for_classify)\n",
    "        self.frames_for_classify = frames_for_classify\n",
    "        self.vote_strategy = vote_strategy\n",
    "\n",
    "    def classify_buffer(self):\n",
    "        if len(self.frames_buffer) == 0:\n",
    "            return None, None\n",
    "        preds = self.eval_model(list(self.frames_buffer), verbose=False)\n",
    "        top1 = [int(p.probs.top1) for p in preds]\n",
    "        if self.vote_strategy == \"majority\":\n",
    "            final_pred = max(set(top1), key=top1.count)\n",
    "        else:\n",
    "            final_pred = top1[-1]\n",
    "        label = self.eval_model.names[final_pred]\n",
    "        confs = [float(p.probs.top1conf) for p in preds]\n",
    "        return label, float(np.mean(confs))\n",
    "\n",
    "    def update(self, frame):\n",
    "        self.frames_buffer.append(frame.copy())\n",
    "        res = self.model(frame, verbose=False)[0]\n",
    "        kps_best = None\n",
    "\n",
    "        if res.keypoints is not None and len(res.keypoints) > 0:\n",
    "            # Select best keypoint set (highest avg confidence)\n",
    "            best_i = 0\n",
    "            best_score = -1\n",
    "            for i, kp in enumerate(res.keypoints):\n",
    "                conf = float(kp.conf.mean())\n",
    "                if conf > best_score:\n",
    "                    best_score = conf\n",
    "                    best_i = i\n",
    "            kps = res.keypoints[best_i].data[0].cpu().numpy()  # (17,3)\n",
    "            kps_best = kps\n",
    "\n",
    "            # Compute mean y of shoulders and hips\n",
    "            y_points = []\n",
    "            for idx in [KS['ls'], KS['rs'], KS['lh'], KS['rh']]:\n",
    "                if kps[idx,2] > 0.35:\n",
    "                    y_points.append(kps[idx,1])\n",
    "            if len(y_points)>=2:\n",
    "                y_mean = float(np.mean(y_points))\n",
    "                self.prev_y.append(y_mean)\n",
    "\n",
    "            if len(self.prev_y) == self.prev_y.maxlen:\n",
    "                dy = self.prev_y[-1] - self.prev_y[0]\n",
    "                # simple hysteresis on y to detect down/up\n",
    "                if self.state == \"up\" and dy > 8:\n",
    "                    self.state = \"down\"\n",
    "                elif self.state == \"down\" and dy < -8:\n",
    "                    self.state = \"up\"\n",
    "                    # Completed a rep\n",
    "                    self.reps += 1\n",
    "                    # Classify the buffered frames around bottom position\n",
    "                    feedback_label, avg_conf = self.classify_buffer()\n",
    "                    issues = assess_form(kps, phase=\"bottom\")\n",
    "                    event = {\n",
    "                        \"rep\": self.reps,\n",
    "                        \"time\": time.time(),\n",
    "                        \"feedback\": feedback_label,\n",
    "                        \"issues\": issues,\n",
    "                        \"kps_conf\": float(np.mean(kps[:,2])),\n",
    "                        \"clf_conf\": avg_conf,\n",
    "                    }\n",
    "                    self.rep_events.append(event)\n",
    "                    return True, event, kps_best\n",
    "\n",
    "        return False, None, kps_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb02e96",
   "metadata": {},
   "source": [
    "# 6.5 teller voor hoeveelheid correct/incorrect frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff09ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 295\n",
      "incorrect 326\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "for cls in [\"correct\",\"incorrect\"]:\n",
    "    n = len(list((Path(\"data/frames/train\")/cls).glob(\"*.jpg\")))\n",
    "    print(cls, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30ed67",
   "metadata": {},
   "source": [
    "# 7. Quick check for my own sanity\n",
    "Checks whether my trained images are in the correct folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f5d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model names: {0: 'correct', 1: 'incorrect'}\n",
      "Copy of push up 46_f00003.jpg {0: 'correct', 1: 'incorrect'} 0 correct 0.9995589852333069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = YOLO(BEST_WEIGHTS)\n",
    "print(\"Model names:\", model.names)\n",
    "\n",
    "correct_list = list((Path(OUTPUT_FRAMES_DIR)/\"test\"/\"correct\").glob(\"*.jpg\"))\n",
    "incorrect_list = list((Path(OUTPUT_FRAMES_DIR)/\"test\"/\"incorrect\").glob(\"*.jpg\"))\n",
    "if correct_list and incorrect_list:\n",
    "    import random\n",
    "    for img_path in [random.choice(correct_list), random.choice(incorrect_list)]:\n",
    "        r = model(str(img_path), verbose=False)[0]\n",
    "    print(\n",
    "        img_path.name,\n",
    "        r.names,\n",
    "        int(r.probs.top1),\n",
    "        r.names[int(r.probs.top1)],\n",
    "        float(r.probs.top1conf)\n",
    "    )\n",
    "else:\n",
    "    print(\"No test images found for quick check.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb68164",
   "metadata": {},
   "source": [
    "## 7.5\n",
    "Quick check for data accuracy and estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88b27a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'correct', 1: 'incorrect'}\n",
      "Copy of push up 132_f00004.jpg: expected=correct  predicted=correct  conf=1.00\n",
      "Copy of push up 46_f00004.jpg: expected=incorrect  predicted=correct  conf=0.99\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "model = YOLO(\"runs/pushup-cls42/weights/best.pt\")\n",
    "print(model.names)\n",
    "\n",
    "for cls in [\"correct\",\"incorrect\"]:\n",
    "    p = random.choice(list((Path(\"data/frames/test\")/cls).glob(\"*.jpg\")))\n",
    "    r = model(str(p), verbose=False)[0]\n",
    "    pred = model.names[int(r.probs.top1)]\n",
    "    conf = float(r.probs.top1conf)\n",
    "    print(f\"{p.name}: expected={cls}  predicted={pred}  conf={conf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5757989b",
   "metadata": {},
   "source": [
    "# 8. Live Push-up Form Test (Webcam) \n",
    "Execute the program and run the yolo webcam + rep counter. Feedback is provided shortly on screen, or in the terminal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa169433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier loaded: {0: 'correct', 1: 'incorrect'}\n",
      "Press 'q' to quit the live test.\n",
      "Rep 1: INCORRECT | Good form!\n",
      "Rep 2: INCORRECT | Good form!\n",
      "Rep 3: INCORRECT | Good form!\n",
      "Rep 4: INCORRECT | Good form!\n",
      "Rep 5: INCORRECT | Good form!\n",
      "Rep 6: INCORRECT | Good form!\n",
      "Rep 7: INCORRECT | Good form!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timle\\AppData\\Local\\Temp\\ipykernel_10160\\1309306314.py:16: DeprecationWarning: Arrays of 2-dimensional vectors are deprecated. Use arrays of 3-dimensional vectors instead. (deprecated in NumPy 2.0)\n",
      "  return np.linalg.norm(np.cross(b-a, a-p)) / (np.linalg.norm(b-a) + 1e-6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep 8: INCORRECT | Depth too shallow (elbows not bent enough), Hips sagging (keep core tight)\n",
      "Rep 9: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 10: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 11: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 12: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 13: INCORRECT | Depth too shallow (elbows not bent enough), Hips sagging (keep core tight)\n",
      "Rep 14: INCORRECT | Good form!\n",
      "Rep 15: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 16: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 17: INCORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 18: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 19: CORRECT | Good form!\n",
      "Rep 20: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 21: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 22: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 23: CORRECT | Depth too shallow (elbows not bent enough)\n",
      "Rep 24: INCORRECT | Depth too shallow (elbows not bent enough)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2, time\n",
    "from pathlib import Path\n",
    "\n",
    "# load models\n",
    "RUNS_DIR = \"runs\"\n",
    "RUN_NAME = \"pushup-cls42\"  # dit updaten naar gewenste run\n",
    "BEST_WEIGHTS = f\"{RUNS_DIR}/{RUN_NAME}/weights/best.pt\"\n",
    "\n",
    "pose_model = YOLO(\"yolov8n-pose.pt\")   \n",
    "clf_model = YOLO(BEST_WEIGHTS)         \n",
    "print(\"Classifier loaded:\", clf_model.names)\n",
    "\n",
    "# rep counter init\n",
    "rep_counter = PoseRepCounter(\n",
    "    pose_model=pose_model,\n",
    "    eval_model=clf_model,\n",
    "    frames_for_classify=7,\n",
    "    vote_strategy=\"majority\"\n",
    ")\n",
    "\n",
    "# webcam setup\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Cannot open webcam\")\n",
    "\n",
    "print(\"Press 'q' to quit the live test.\")\n",
    "\n",
    "# feedback timer\n",
    "feedback_text = \"\"\n",
    "feedback_end_time = 0\n",
    "\n",
    "# optional video recorder\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# out = cv2.VideoWriter(\"pushup_session.mp4\", fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # mirror image\n",
    "    counted, event, kps = rep_counter.update(frame)\n",
    "\n",
    "    # rep counter on screen\n",
    "    text = f\"Reps: {rep_counter.reps}\"\n",
    "    cv2.putText(frame, text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 2)\n",
    "\n",
    "    # feedback on screen\n",
    "    if counted and event:\n",
    "        feedback = event.get(\"feedback\", \"unknown\")\n",
    "        issues = \", \".join(event.get(\"issues\", [])) or \"Good form!\"\n",
    "        print(f\"Rep {event['rep']}: {feedback.upper()} | {issues}\")\n",
    "        feedback_text = f\"{feedback.upper()} - {issues}\"\n",
    "        feedback_end_time = time.time() + 3  # Show for 3 seconds\n",
    "    \n",
    "    # display feedback if timer hasn't expired\n",
    "    if time.time() < feedback_end_time:\n",
    "        cv2.putText(frame, feedback_text, (10, 80),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2)\n",
    "\n",
    "    # Display window\n",
    "    cv2.imshow(\"Push-up Form Tracker\", frame)\n",
    "\n",
    "    # optional write to output video\n",
    "    # out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# out.release()"
   ]
  }
 ],
 "metadata": {
  "created": "2025-11-01T16:22:55.964391Z",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
