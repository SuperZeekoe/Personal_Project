{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f8227e4",
   "metadata": {},
   "source": [
    "# Pushup Form Checker (Final Fixed Version)\n",
    "\n",
    "This notebook implements a hybrid approach to Pushup Form checking:\n",
    "1. **Geometric Analysis:** Uses specific angles (elbows, hips) to judge form (The \"White Box\" approach).\n",
    "2. **AI Classifier:** Uses a lightweight YOLOv8-Classifier trained on your dataset to verify the result.\n",
    "\n",
    "### Fixes Implemented:\n",
    "* **Model Mismatch Fixed:** Now uses `yolov8n-cls.pt` for classification training instead of `pose`.\n",
    "* **Overfitting Fixed:** Epochs reduced to 15, Patience set to 5.\n",
    "* **Visual Feedback:** Draws the skeleton and changes color based on form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbec6090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (8.3.203)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (1.16.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.9.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (0.24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (1.33.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\timle\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\timle\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Device selected for Training & Inference: cpu\n",
      "----------------------------------------\n",
      "Configuration set. Run next cell to start training.\n"
     ]
    }
   ],
   "source": [
    "# 1. Installs & Imports\n",
    "%pip install ultralytics opencv-python numpy pandas matplotlib\n",
    "%pip install scikit-learn joblib\n",
    "\n",
    "import cv2, os, math, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch # Import PyTorch to check for CUDA\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- GPU/CPU Device Selection ---\n",
    "# This logic mirrors your existing project. It checks for a CUDA-compatible GPU.\n",
    "# If CUDA is available, it uses device index 0 (the first GPU); otherwise, it uses 'cpu'.\n",
    "DEVICE = 0 if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device selected for Training & Inference: {DEVICE}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# UPDATE THIS PATH TO YOUR ACTUAL DATA LOCATION IF NECESSARY\n",
    "DATASET_DIR = \"C:/Data/hboict/Sem7-AIFS/Personal_Project\" \n",
    "OUTPUT_FRAMES_DIR = \"data/frames_v2\"\n",
    "RUNS_DIR = \"runs\"\n",
    "RUN_BASE_NAME = \"pushup-cls-v2\" # YOLO will auto-increment this (e.g., v22, v23)\n",
    "\n",
    "# Hyperparameters (Optimized to prevent overfitting)\n",
    "TRAINING_EPOCHS = 4\n",
    "TRAINING_PATIENCE = 1 \n",
    "\n",
    "# Define Keypoint Indices for YOLOv8-Pose\n",
    "KS = {\n",
    "    \"nose\": 0, \"ls\": 5, \"rs\": 6, \"le\": 7, \"re\": 8, \"lw\": 9, \"rw\": 10, \n",
    "    \"lh\": 11, \"rh\": 12, \"lk\": 13, \"rk\": 14, \"la\": 15, \"ra\": 16\n",
    "}\n",
    "\n",
    "print(\"Configuration set. Run next cell to start training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd31e53",
   "metadata": {},
   "source": [
    "### 1.5 Gathering new frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5075e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 921 frames for 'Correct Sequence' and split into T/V/T.\n",
      "Extracted 1304 frames for 'Wrong Sequence' and split into T/V/T.\n",
      "\n",
      "--- Summary ---\n",
      "✅ Extraction Complete! Total Frames: 2225\n",
      "New data ready in: data\\frames_v2\n",
      "Old data folder was: data/frames. New folder is: data/frames_v2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Base directory where your 'Correct Sequence' and 'Wrong Sequence' video folders live\n",
    "DATASET_DIR = Path(\"C:/Data/hboict/Sem7-AIFS/Personal_Project\") \n",
    "\n",
    "# Output directory for the new, large dataset (Make sure this is set in Cell 1 config later!)\n",
    "OUTPUT_FRAMES_V2_DIR = Path(\"data/frames_v2\") \n",
    "\n",
    "# Adjust this number to control the data multiplier:\n",
    "# 1 = extract every frame (massive data)\n",
    "# 5 = extract every 5th frame (recommended multiplier ~5-10x)\n",
    "FRAME_SKIP = 5 \n",
    "# ---------------------\n",
    "\n",
    "def extract_and_split_data(video_folder_name, output_base_dir):\n",
    "    \"\"\"Extracts frames from all videos in a source folder, saving them to new T/V/T splits.\"\"\"\n",
    "    source_dir = DATASET_DIR / video_folder_name\n",
    "    \n",
    "    # Create all output directories upfront: train/correct, val/correct, etc.\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    for split in splits:\n",
    "        (output_base_dir / split / video_folder_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    video_files = list(source_dir.glob(\"*.mp4\"))\n",
    "    \n",
    "    # --- Split Video Files (70% train, 15% val, 15% test) ---\n",
    "    random.shuffle(video_files)\n",
    "    total_videos = len(video_files)\n",
    "    train_split_count = int(total_videos * 0.7)\n",
    "    val_split_count = int(total_videos * 0.15)\n",
    "    \n",
    "    train_files = video_files[:train_split_count]\n",
    "    val_files = video_files[train_split_count:train_split_count + val_split_count]\n",
    "    test_files = video_files[train_split_count + val_split_count:]\n",
    "    \n",
    "    file_map = {\"train\": train_files, \"val\": val_files, \"test\": test_files}\n",
    "\n",
    "    total_frames_extracted = 0\n",
    "    \n",
    "    for split, files in file_map.items():\n",
    "        for video_path in files:\n",
    "            cap = cv2.VideoCapture(str(video_path))\n",
    "            frame_count = 0\n",
    "            frames_saved_from_video = 0\n",
    "            \n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Sample every FRAME_SKIP frame\n",
    "                if frame_count % FRAME_SKIP == 0:\n",
    "                    # Naming convention includes video name and frame number\n",
    "                    output_file_name = f\"{video_path.stem}_f{frame_count}.jpg\"\n",
    "                    output_path = output_base_dir / split / video_folder_name / output_file_name\n",
    "                    cv2.imwrite(str(output_path), frame)\n",
    "                    frames_saved_from_video += 1\n",
    "                \n",
    "                frame_count += 1\n",
    "            \n",
    "            cap.release()\n",
    "            total_frames_extracted += frames_saved_from_video\n",
    "            \n",
    "    print(f\"Extracted {total_frames_extracted} frames for '{video_folder_name}' and split into T/V/T.\")\n",
    "    return total_frames_extracted\n",
    "\n",
    "def run_extraction_pipeline():\n",
    "    # 1. Clean up old data structure if desired (optional)\n",
    "    if OUTPUT_FRAMES_V2_DIR.exists():\n",
    "        print(f\"Clearing old directory: {OUTPUT_FRAMES_V2_DIR}\")\n",
    "        shutil.rmtree(OUTPUT_FRAMES_V2_DIR)\n",
    "        \n",
    "    # 2. Run extraction for both classes\n",
    "    total_correct = extract_and_split_data(\"Correct Sequence\", OUTPUT_FRAMES_V2_DIR)\n",
    "    total_incorrect = extract_and_split_data(\"Wrong Sequence\", OUTPUT_FRAMES_V2_DIR)\n",
    "    \n",
    "    print(\"\\n--- Summary ---\")\n",
    "    print(f\"✅ Extraction Complete! Total Frames: {total_correct + total_incorrect}\")\n",
    "    print(f\"New data ready in: {OUTPUT_FRAMES_V2_DIR}\")\n",
    "    print(f\"Old data folder was: data/frames. New folder is: data/frames_v2\")\n",
    "\n",
    "run_extraction_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81285b",
   "metadata": {},
   "source": [
    "## 1.75?\n",
    "SEt images to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3036fa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8 Pose Model loaded successfully from 'yolov8n-pose.pt'.\n",
      "Processing 1543 images for TRAIN split...\n",
      "✅ TRAIN Data Generated: 7715 robust samples. Saved to pushup_dataset_robust_train.csv\n",
      "   Class Balance: {'incorrect': 4465, 'correct': 3250}\n",
      "Processing 376 images for VAL split...\n",
      "✅ VAL Data Generated: 1880 robust samples. Saved to pushup_dataset_robust_val.csv\n",
      "   Class Balance: {'incorrect': 1190, 'correct': 690}\n",
      "Processing 306 images for TEST split...\n",
      "✅ TEST Data Generated: 1530 robust samples. Saved to pushup_dataset_robust_test.csv\n",
      "   Class Balance: {'incorrect': 865, 'correct': 665}\n",
      "\n",
      "--- Total Robust Samples Generated: 11125 ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "from math import sqrt\n",
    "from ultralytics import YOLO # <-- REQUIRED IMPORT for Keypoint Detection\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# The input is the direct output of Cell 1.5 (the image frames)\n",
    "FRAME_INPUT_DIR = Path('data/frames_v2') \n",
    "OUTPUT_BASE_DIR = Path('.') # Save the final CSVs in the root directory\n",
    "\n",
    "# Initialize Pose Model\n",
    "POSE_MODEL_PATH = \"yolov8n-pose.pt\"\n",
    "try:\n",
    "    pose_model = YOLO(POSE_MODEL_PATH) \n",
    "    print(f\"YOLOv8 Pose Model loaded successfully from '{POSE_MODEL_PATH}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}. Please ensure '{POSE_MODEL_PATH}' is available.\")\n",
    "    pose_model = None\n",
    "\n",
    "# --- Keypoint Structure ---\n",
    "# This dictionary maps joint names to the index used by the 17-point COCO model\n",
    "KS = {\n",
    "    'nose': 0, 'le': 3, 're': 4, 'ls': 5, 'rs': 6, 'le': 7, 're': 8,\n",
    "    'lw': 9, 'rw': 10, 'lh': 11, 'rh': 12, 'lk': 13, 'rk': 14,\n",
    "    'la': 15, 'ra': 16\n",
    "}\n",
    "\n",
    "# --- Helper Functions (Robust Features) ---\n",
    "\n",
    "def calculate_angle(kps, p1, p2, p3):\n",
    "    \"\"\"Calculates the angle (in degrees) between three keypoints, centered at p2.\"\"\"\n",
    "    p1_coords = kps[p1][:2]\n",
    "    p2_coords = kps[p2][:2]\n",
    "    p3_coords = kps[p3][:2]\n",
    "    \n",
    "    v1 = np.array(p1_coords) - np.array(p2_coords)\n",
    "    v2 = np.array(p3_coords) - np.array(p2_coords)\n",
    "    \n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    \n",
    "    if norm_v1 == 0 or norm_v2 == 0:\n",
    "        return 180.0\n",
    "        \n",
    "    angle_rad = np.arccos(np.clip(dot_product / (norm_v1 * norm_v2), -1.0, 1.0))\n",
    "    return np.degrees(angle_rad)\n",
    "\n",
    "def create_robust_features(kps):\n",
    "    \"\"\"Creates a 20-feature vector using angles and distance ratios (Invariant to rotation/scale).\"\"\"\n",
    "    features = []\n",
    "\n",
    "    def dist(p1, p2):\n",
    "        return np.linalg.norm(kps[p1, :2] - kps[p2, :2])\n",
    "\n",
    "    # 1. 8 Angles (Joint Flexure)\n",
    "    features.append(calculate_angle(kps, KS['rw'], KS['re'], KS['rs']))\n",
    "    features.append(calculate_angle(kps, KS['lw'], KS['le'], KS['ls']))\n",
    "    features.append(calculate_angle(kps, KS['re'], KS['rs'], KS['rh']))\n",
    "    features.append(calculate_angle(kps, KS['le'], KS['ls'], KS['lh']))\n",
    "    features.append(calculate_angle(kps, KS['rs'], KS['rh'], KS['rk']))\n",
    "    features.append(calculate_angle(kps, KS['ls'], KS['lh'], KS['lk']))\n",
    "    features.append(calculate_angle(kps, KS['rh'], KS['rk'], KS['ra']))\n",
    "    features.append(calculate_angle(kps, KS['lh'], KS['lk'], KS['la']))\n",
    "\n",
    "    # 2. 12 Distance Ratios\n",
    "    torso_length = (dist(KS['ls'], KS['lh']) + dist(KS['rs'], KS['rh'])) / 2\n",
    "    if torso_length == 0: torso_length = 1.0\n",
    "\n",
    "    features.append(dist(KS['rs'], KS['re']) / torso_length) \n",
    "    features.append(dist(KS['re'], KS['rw']) / torso_length) \n",
    "    features.append(dist(KS['ls'], KS['le']) / torso_length) \n",
    "    features.append(dist(KS['le'], KS['lw']) / torso_length) \n",
    "    features.append(dist(KS['rs'], KS['ls']) / torso_length) \n",
    "    features.append(dist(KS['rh'], KS['lh']) / torso_length) \n",
    "    features.append(dist(KS['rh'], KS['rk']) / torso_length) \n",
    "    features.append(dist(KS['rk'], KS['ra']) / torso_length) \n",
    "    features.append(dist(KS['lh'], KS['lk']) / torso_length) \n",
    "    features.append(dist(KS['lk'], KS['la']) / torso_length) \n",
    "    features.append(dist(KS['nose'], KS['rs']) / torso_length) \n",
    "    features.append(dist(KS['nose'], KS['ls']) / torso_length) \n",
    "    \n",
    "    return features\n",
    "\n",
    "def augment_and_extract(kps, num_augmentations=5):\n",
    "    \"\"\"Applies small random noise/scaling to keypoints and extracts features multiple times.\"\"\"\n",
    "    \n",
    "    all_features = []\n",
    "    \n",
    "    # 1. Base features (non-augmented)\n",
    "    all_features.append(create_robust_features(kps.copy()))\n",
    "    \n",
    "    # 2. Augmentations (4 more times)\n",
    "    for _ in range(num_augmentations - 1):\n",
    "        kps_aug = kps.copy()\n",
    "        \n",
    "        # Random Scaling: +/- 5% \n",
    "        scale_factor = 1 + random.uniform(-0.05, 0.05) \n",
    "        kps_aug[:, :2] *= scale_factor\n",
    "        \n",
    "        # Random Noise: +/- 0.002 (Simulates minor detection flicker)\n",
    "        noise = np.random.uniform(-0.002, 0.002, size=kps_aug[:, :2].shape)\n",
    "        kps_aug[:, :2] += noise\n",
    "        \n",
    "        all_features.append(create_robust_features(kps_aug))\n",
    "\n",
    "    return all_features\n",
    "\n",
    "\n",
    "# --- Main Data Creation Loop ---\n",
    "\n",
    "if pose_model:\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    feature_names = (\n",
    "        [f'angle_{i}' for i in range(8)] + \n",
    "        [f'ratio_{i}' for i in range(12)] + \n",
    "        ['label']\n",
    "    )\n",
    "        \n",
    "    total_samples = 0\n",
    "    for split in splits:\n",
    "        all_data = []\n",
    "        split_dir = FRAME_INPUT_DIR / split\n",
    "        \n",
    "        if not split_dir.exists():\n",
    "            print(f\"⚠️ Skipping {split}: Frame directory not found at {split_dir}.\")\n",
    "            continue\n",
    "            \n",
    "        # Search recursively for image files (.jpg)\n",
    "        image_files = list(split_dir.glob(\"*/*.jpg\"))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"⚠️ No image files found in {split_dir}.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Processing {len(image_files)} images for {split.upper()} split...\")\n",
    "\n",
    "        for filepath in image_files:\n",
    "            # 1. Get Label\n",
    "            label_raw = filepath.parent.name\n",
    "            label = None\n",
    "            if 'correct' in label_raw.lower():\n",
    "                label = 'correct'\n",
    "            elif 'wrong' in label_raw.lower():\n",
    "                label = 'incorrect'\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # 2. Keypoint Detection (Inference)\n",
    "                # Using the string representation of Path object for YOLO input\n",
    "                results = pose_model(str(filepath), verbose=False)\n",
    "                \n",
    "                # Check if a person was detected\n",
    "                if results and results[0].keypoints.xyn.shape[0] > 0:\n",
    "                    \n",
    "                    # Extract normalized coordinates (xyn) and confidence\n",
    "                    xy_normalized = results[0].keypoints.xyn[0].cpu().numpy()\n",
    "                    conf_values = results[0].keypoints.conf[0].cpu().numpy().reshape(-1, 1)\n",
    "                    # Keypoints in [x, y, confidence] format (normalized to 0-1)\n",
    "                    kps_normalized_xyc = np.concatenate((xy_normalized, conf_values), axis=1)\n",
    "                    \n",
    "                    if kps_normalized_xyc.shape == (17, 3):\n",
    "                        # 3. Augment and Extract Features\n",
    "                        robust_feature_vectors = augment_and_extract(kps_normalized_xyc, num_augmentations=5)\n",
    "                        \n",
    "                        for features in robust_feature_vectors:\n",
    "                            features.append(label)\n",
    "                            all_data.append(features)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                # print(f\"Skipping file {filepath.name} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "        # 4. Save Final DataFrame for the split\n",
    "        df_robust = pd.DataFrame(all_data, columns=feature_names)\n",
    "        output_filename = f'pushup_dataset_robust_{split}.csv'\n",
    "        df_robust.to_csv(OUTPUT_BASE_DIR / output_filename, index=False)\n",
    "        \n",
    "        total_samples += len(df_robust)\n",
    "        print(f\"✅ {split.upper()} Data Generated: {len(df_robust)} robust samples. Saved to {output_filename}\")\n",
    "        print(f\"   Class Balance: {df_robust['label'].value_counts().to_dict()}\")\n",
    "\n",
    "    print(f\"\\n--- Total Robust Samples Generated: {total_samples} ---\")\n",
    "else:\n",
    "    print(\"Cannot run data creation: YOLO model failed to load.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74dfe14",
   "metadata": {},
   "source": [
    "### 2. Train the Classifier (Correctly)\n",
    "We use `yolov8n-cls.pt` (Classification model) and stricter settings to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e767534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation on Internal Test Split ---\n",
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     correct       1.00      1.00      1.00       488\n",
      "   incorrect       1.00      1.00      1.00       670\n",
      "\n",
      "    accuracy                           1.00      1158\n",
      "   macro avg       1.00      1.00      1.00      1158\n",
      "weighted avg       1.00      1.00      1.00      1158\n",
      "\n",
      "✅ Model saved as 'pose_classifier_robust.pkl'\n"
     ]
    }
   ],
   "source": [
    "# def train_classifier():\n",
    "#     # Load the CLASSIFICATION model (yolov8n-cls.pt)\n",
    "#     model = YOLO('yolov8n-cls.pt')  \n",
    "\n",
    "#     print(f\"Starting training on device: {DEVICE}\")\n",
    "#     results = model.train(\n",
    "#         data=OUTPUT_FRAMES_DIR,  \n",
    "#         epochs=TRAINING_EPOCHS,    \n",
    "#         patience=TRAINING_PATIENCE, \n",
    "#         imgsz=224,               \n",
    "#         project=RUNS_DIR,        \n",
    "#         name=RUN_BASE_NAME,      \n",
    "#         batch=64,                \n",
    "#         augment=True,            \n",
    "#         device=DEVICE,           # <-- FORCES GPU USAGE\n",
    "#         exist_ok=False      # for automatic run counting\n",
    "#     )\n",
    "#     return results\n",
    "\n",
    "# # Run training\n",
    "# train_classifier()\n",
    "# print(\"\\nTraining Complete. Best weights saved.\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "def train_pose_classifier():\n",
    "    # --- CONFIGURATION ---\n",
    "    # ⚠️ IMPORTANT: Load the robust, augmented training data.\n",
    "    CSV_PATH = 'pushup_dataset_robust_train.csv' \n",
    "    MODEL_SAVE_PATH = 'pose_classifier_robust.pkl'\n",
    "    \n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: CSV file not found at {CSV_PATH}. Run the corrected Cell 1.75 first.\")\n",
    "        return\n",
    "        \n",
    "    X = df.drop(\"label\", axis=1)\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    # 2. Split (using a small validation set from the already prepared training data)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.15, # Use a smaller test set here (15%)\n",
    "        random_state=42,\n",
    "        stratify=y       # Ensure balanced classes in the split\n",
    "    )\n",
    "    \n",
    "    # 3. Train Random Forest (The \"Brain\")\n",
    "    # Added hyperparameter optimization: max_depth to prevent minor overfitting \n",
    "    # to noisy augmented features.\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=150,       # Slight increase in trees for better generalization\n",
    "        max_depth=15,           # Limits tree depth to prevent deep overfitting\n",
    "        random_state=42,\n",
    "        class_weight='balanced' # Highly recommended due to potential data imbalance\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # 4. Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"--- Model Evaluation on Internal Test Split ---\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    # 5. Save Model\n",
    "    joblib.dump(clf, MODEL_SAVE_PATH)\n",
    "    print(f\"✅ Model saved as '{MODEL_SAVE_PATH}'\")\n",
    "\n",
    "train_pose_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ec7a85",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11eed67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best params: {'n_estimators': 160, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 6}\n",
      "Best CV recall(correct): 0.5584615384615385\n",
      "\n",
      "--- VAL SET PERFORMANCE (tuned RF) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct       0.51      0.82      0.63       690\n",
      "   incorrect       0.84      0.55      0.67      1190\n",
      "\n",
      "    accuracy                           0.65      1880\n",
      "   macro avg       0.68      0.69      0.65      1880\n",
      "weighted avg       0.72      0.65      0.65      1880\n",
      "\n",
      "\n",
      "Saved tuned RF model as 'pose_classifier_robust_tuned.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# --- Load TRAIN and VAL for tuning ---\n",
    "df_train = pd.read_csv(\"pushup_dataset_robust_train.csv\")\n",
    "df_val   = pd.read_csv(\"pushup_dataset_robust_val.csv\")\n",
    "\n",
    "X_train = df_train.drop(\"label\", axis=1)\n",
    "y_train = df_train[\"label\"]\n",
    "\n",
    "X_val = df_val.drop(\"label\", axis=1)\n",
    "y_val = df_val[\"label\"]\n",
    "\n",
    "# --- Custom scorer: emphasize recall on the 'correct' class ---\n",
    "def recall_correct(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, pos_label='correct')\n",
    "\n",
    "recall_correct_scorer = make_scorer(recall_correct)\n",
    "\n",
    "# --- Base RF ---\n",
    "rf_base = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- Hyperparameter search space ---\n",
    "param_dist = {\n",
    "    \"n_estimators\":   [80, 120, 160, 220],\n",
    "    \"max_depth\":      [6, 8, 10, 12],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\":  [1, 2, 4],\n",
    "    \"max_features\":   [\"sqrt\", \"log2\", 0.5]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    rf_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,             # you can bump this up if it runs fast\n",
    "    scoring=recall_correct_scorer,  # prioritise catching 'correct' reps\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(\"Best CV recall(correct):\", search.best_score_)\n",
    "\n",
    "# Evaluate the tuned model on VAL set\n",
    "best_rf = search.best_estimator_\n",
    "y_val_pred = best_rf.predict(X_val)\n",
    "print(\"\\n--- VAL SET PERFORMANCE (tuned RF) ---\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Save tuned model for later test + live loop\n",
    "joblib.dump(best_rf, \"pose_classifier_robust_tuned.pkl\")\n",
    "print(\"\\nSaved tuned RF model as 'pose_classifier_robust_tuned.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffde9a0",
   "metadata": {},
   "source": [
    "## number whatever, visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3b61567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving all visualizations and reports to folder: rf_visuals\\20251207_154719\n",
      "\n",
      "Plot 1/5: Class distribution saved.\n",
      "Plot 2/5: Feature importance saved.\n",
      "Plot 3/5: Confusion Matrix (Raw) saved.\n",
      "Plot 4/5: Confusion Matrix (Normalized) saved.\n",
      "\n",
      "--- CLASSIFICATION REPORT (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct       0.89      0.81      0.85       665\n",
      "   incorrect       0.86      0.92      0.89       865\n",
      "\n",
      "    accuracy                           0.87      1530\n",
      "   macro avg       0.88      0.87      0.87      1530\n",
      "weighted avg       0.88      0.87      0.87      1530\n",
      "\n",
      "Numerical report saved to 'rf_visuals\\20251207_154719\\classification_report.txt'.\n",
      "Plot 5/5: Learning-curve style metrics saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import learning_curve  # <-- NEW\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "TRAIN_CSV_PATH = \"pushup_dataset_robust_train.csv\"\n",
    "TEST_CSV_PATH  = \"pushup_dataset_robust_test.csv\"\n",
    "MODEL_PATH     = \"pose_classifier_robust.pkl\"\n",
    "\n",
    "# --- FOLDER SETUP ---\n",
    "BASE_VIS_DIR = \"rf_visuals\"\n",
    "RUN_ID = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_DIR = os.path.join(BASE_VIS_DIR, RUN_ID)\n",
    "\n",
    "# --- FEATURE DEFINITION MAP ---\n",
    "FEATURE_MAP = {\n",
    "    'angle_0': 'R Elbow Angle', 'angle_1': 'L Elbow Angle',\n",
    "    'angle_2': 'R Shoulder Angle', 'angle_3': 'L Shoulder Angle',\n",
    "    'angle_4': 'R Hip (Torso) Angle', 'angle_5': 'L Hip (Torso) Angle',\n",
    "    'angle_6': 'R Knee Angle', 'angle_7': 'L Knee Angle',\n",
    "    'ratio_0': 'R Shoulder-Elbow / Torso', 'ratio_1': 'R Elbow-Wrist / Torso',\n",
    "    'ratio_2': 'L Shoulder-Elbow / Torso', 'ratio_3': 'L Elbow-Wrist / Torso',\n",
    "    'ratio_4': 'Shoulder Width / Torso', 'ratio_5': 'Hip Width / Torso',\n",
    "    'ratio_6': 'R Hip-Knee / Torso', 'ratio_7': 'R Knee-Ankle / Torso',\n",
    "    'ratio_8': 'L Hip-Knee / Torso', 'ratio_9': 'L Knee-Ankle / Torso',\n",
    "    'ratio_10': 'Nose-R Shoulder / Torso', 'ratio_11': 'Nose-L Shoulder / Torso',\n",
    "}\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    print(f\"Saving all visualizations and reports to folder: {OUTPUT_DIR}\\n\")\n",
    "\n",
    "    # 1. Load data + model\n",
    "    df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    df_test  = pd.read_csv(TEST_CSV_PATH)\n",
    "    rf_model = joblib.load(MODEL_PATH)\n",
    "\n",
    "    # 2. Prepare TEST data (NO re-splitting)\n",
    "    X_test = df_test.drop(\"label\", axis=1)\n",
    "    y_test = df_test[\"label\"]\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # --- VIS 1: Class distribution (test set) ---\n",
    "    class_counts = y_test.value_counts().sort_index()\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    bars = plt.bar(class_counts.index, class_counts.values,\n",
    "                   color=['skyblue', 'lightcoral'])\n",
    "    plt.title('1. Class Distribution (Test Set): Correct vs. Incorrect Poses')\n",
    "    plt.xlabel('Pose Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, h + 5, str(int(h)),\n",
    "                 ha='center', va='bottom')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'class_distribution.png'))\n",
    "    plt.close()\n",
    "    print(\"Plot 1/5: Class distribution saved.\")\n",
    "\n",
    "    # --- VIS 2: Feature importance ---\n",
    "    feature_names = [f'angle_{i}' for i in range(8)] + [f'ratio_{i}' for i in range(12)]\n",
    "    importances = rf_model.feature_importances_\n",
    "\n",
    "    fi_df = (pd.DataFrame({'Feature': feature_names,\n",
    "                           'Importance': importances})\n",
    "               .sort_values(by='Importance', ascending=False))\n",
    "    fi_df['Description'] = fi_df['Feature'].map(FEATURE_MAP)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = fi_df.head(15)\n",
    "    plt.barh(top_features['Description'], top_features['Importance'], color='purple')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('2. Random Forest Feature Importance (Robust Features)')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Feature Description')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'feature_importance.png'))\n",
    "    plt.close()\n",
    "    print(\"Plot 2/5: Feature importance saved.\")\n",
    "\n",
    "    # --- VIS 3: Confusion matrix (raw counts) ---\n",
    "    labels = sorted(df_test['label'].unique())\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    disp.plot(cmap=plt.cm.Blues, values_format='d', ax=plt.gca())\n",
    "    plt.title('3. Confusion Matrix (Raw Counts)')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix_raw.png'))\n",
    "    plt.close()\n",
    "    print(\"Plot 3/5: Confusion Matrix (Raw) saved.\")\n",
    "\n",
    "    # --- VIS 4: Confusion matrix (normalized) ---\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    disp_norm = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=labels)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    disp_norm.plot(cmap=plt.cm.Greens, values_format='.2f', ax=plt.gca())\n",
    "    plt.title('4. Confusion Matrix (Normalized Percentages)')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix_normalized.png'))\n",
    "    plt.close()\n",
    "    print(\"Plot 4/5: Confusion Matrix (Normalized) saved.\")\n",
    "\n",
    "    # --- Classification report (same as you printed) ---\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    report_path = os.path.join(OUTPUT_DIR, 'classification_report.txt')\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(report)\n",
    "\n",
    "    print(\"\\n--- CLASSIFICATION REPORT (Test Set) ---\")\n",
    "    print(report)\n",
    "    print(f\"Numerical report saved to '{report_path}'.\")\n",
    "\n",
    "    # --- VIS 5: \"results.png\"-style learning-curve plot ---------------------\n",
    "\n",
    "    # Use training data for learning curve\n",
    "    X_train_lc = df_train.drop(\"label\", axis=1)\n",
    "    y_train_lc = df_train[\"label\"]\n",
    "\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        rf_model,\n",
    "        X_train_lc,\n",
    "        y_train_lc,\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    train_mean = train_scores.mean(axis=1)\n",
    "    val_mean   = val_scores.mean(axis=1)\n",
    "\n",
    "    # Treat \"loss\" as 1 - accuracy (just for plotting)\n",
    "    loss_train = 1.0 - train_mean\n",
    "    loss_val   = 1.0 - val_mean\n",
    "\n",
    "    def smooth_curve(y, window=3):\n",
    "        \"\"\"Simple moving-average smoothing.\"\"\"\n",
    "        if len(y) <= window:\n",
    "            return y\n",
    "        kernel = np.ones(window) / window\n",
    "        return np.convolve(y, kernel, mode=\"same\")\n",
    "\n",
    "    train_mean_s = smooth_curve(train_mean)\n",
    "    val_mean_s   = smooth_curve(val_mean)\n",
    "    loss_train_s = smooth_curve(loss_train)\n",
    "    loss_val_s   = smooth_curve(loss_val)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "    # top-left: train loss\n",
    "    axes[0, 0].plot(train_sizes, loss_train, marker=\"o\", label=\"results\")\n",
    "    axes[0, 0].plot(train_sizes, loss_train_s, linestyle=\"dotted\", label=\"smooth\")\n",
    "    axes[0, 0].set_title(\"train/loss\")\n",
    "    axes[0, 0].set_xlabel(\"Training samples\")\n",
    "    axes[0, 0].set_ylabel(\"Loss (1 - accuracy)\")\n",
    "\n",
    "    # top-right: train accuracy\n",
    "    axes[0, 1].plot(train_sizes, train_mean, marker=\"o\", label=\"results\")\n",
    "    axes[0, 1].plot(train_sizes, train_mean_s, linestyle=\"dotted\", label=\"smooth\")\n",
    "    axes[0, 1].set_title(\"metrics/accuracy_train\")\n",
    "    axes[0, 1].set_xlabel(\"Training samples\")\n",
    "    axes[0, 1].set_ylabel(\"Accuracy\")\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "    # bottom-left: val loss\n",
    "    axes[1, 0].plot(train_sizes, loss_val, marker=\"o\", label=\"results\")\n",
    "    axes[1, 0].plot(train_sizes, loss_val_s, linestyle=\"dotted\", label=\"smooth\")\n",
    "    axes[1, 0].set_title(\"val/loss\")\n",
    "    axes[1, 0].set_xlabel(\"Training samples\")\n",
    "    axes[1, 0].set_ylabel(\"Loss (1 - accuracy)\")\n",
    "\n",
    "    # bottom-right: val accuracy\n",
    "    axes[1, 1].plot(train_sizes, val_mean, marker=\"o\", label=\"results\")\n",
    "    axes[1, 1].plot(train_sizes, val_mean_s, linestyle=\"dotted\", label=\"smooth\")\n",
    "    axes[1, 1].set_title(\"metrics/accuracy_val\")\n",
    "    axes[1, 1].set_xlabel(\"Training samples\")\n",
    "    axes[1, 1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "    for ax in axes.flat:\n",
    "        ax.grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    curve_path = os.path.join(OUTPUT_DIR, \"learning_curves.png\")\n",
    "    fig.savefig(curve_path)\n",
    "    plt.close(fig)\n",
    "    print(\"Plot 5/5: Learning-curve style metrics saved.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(\"\\n--- ERROR ---\")\n",
    "    print(f\"Required file not found: {e.filename}. Make sure the CSVs and model exist before running this cell.\")\n",
    "except Exception as e:\n",
    "    print(\"\\n--- FATAL ERROR DURING VISUALIZATION ---\")\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588717b",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd2aa3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct       0.89      0.81      0.85       665\n",
      "   incorrect       0.86      0.92      0.89       865\n",
      "\n",
      "    accuracy                           0.87      1530\n",
      "   macro avg       0.88      0.87      0.87      1530\n",
      "weighted avg       0.88      0.87      0.87      1530\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pose_classifier_robust.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Train on the dedicated TRAIN CSV\n",
    "df_train = pd.read_csv(\"pushup_dataset_robust_train.csv\")\n",
    "X_train = df_train.drop(\"label\", axis=1)\n",
    "y_train = df_train[\"label\"]\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=15,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test on the completely separate TEST CSV\n",
    "df_test = pd.read_csv(\"pushup_dataset_robust_test.csv\")\n",
    "X_test = df_test.drop(\"label\", axis=1)\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# (optional) overwrite the model used by the live loop\n",
    "import joblib\n",
    "joblib.dump(clf, \"pose_classifier_robust.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e2436",
   "metadata": {},
   "source": [
    "### 3. Geometric Logic Helper Functions\n",
    "These functions calculate angles to check for depth and hip sag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd4e0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def calculate_angle(a, b, c):\n",
    "#     \"\"\"Calculates angle ABC (in degrees) where B is the vertex.\"\"\"\n",
    "#     a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "#     ba = a - b\n",
    "#     bc = c - b\n",
    "    \n",
    "#     norm_ba = np.linalg.norm(ba)\n",
    "#     norm_bc = np.linalg.norm(bc)\n",
    "#     if norm_ba == 0 or norm_bc == 0:\n",
    "#         return 180.0\n",
    "        \n",
    "#     cosine_angle = np.dot(ba, bc) / (norm_ba * norm_bc)\n",
    "#     angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "#     return np.degrees(angle)\n",
    "\n",
    "# def get_xy(kps, index):\n",
    "#     \"\"\"Safe helper to get (x, y) tuple from keypoints.\"\"\"\n",
    "#     return (float(kps[index, 0]), float(kps[index, 1]))\n",
    "\n",
    "# def get_best_elbow_angle(kps):\n",
    "#     \"\"\"\n",
    "#     Returns the best elbow angle (left or right) based on confidence.\n",
    "#     Falls back to None if nothing reliable is found.\n",
    "#     \"\"\"\n",
    "#     # Assuming KS (Keypoint Skeleton) is defined in your environment\n",
    "#     if 'ls' not in KS or 'le' not in KS or 'lw' not in KS:\n",
    "#         return None\n",
    "        \n",
    "#     left_conf = kps[KS['ls'], 2] * kps[KS['le'], 2] * kps[KS['lw'], 2]\n",
    "#     right_conf = kps[KS['rs'], 2] * kps[KS['re'], 2] * kps[KS['rw'], 2]\n",
    "    \n",
    "#     elbow_angle = None\n",
    "    \n",
    "#     if left_conf > right_conf and left_conf > 0.5:\n",
    "#         elbow_angle = calculate_angle(\n",
    "#             get_xy(kps, KS['ls']),\n",
    "#             get_xy(kps, KS['le']),\n",
    "#             get_xy(kps, KS['lw'])\n",
    "#         )\n",
    "#     elif right_conf > 0.5:\n",
    "#         elbow_angle = calculate_angle(\n",
    "#             get_xy(kps, KS['rs']),\n",
    "#             get_xy(kps, KS['re']),\n",
    "#             get_xy(kps, KS['rw'])\n",
    "#         )\n",
    "    \n",
    "#     return elbow_angle\n",
    "\n",
    "# def assess_form_geometric(kps, phase=\"top\", bottom_elbow_angle=None):\n",
    "#     \"\"\"\n",
    "#     Returns a list of issues based on geometry (angles / alignment).\n",
    "#     Lockout check removed for stability.\n",
    "#     \"\"\"\n",
    "#     issues = []\n",
    "    \n",
    "#     # --- 1. ELBOW ANGLES: DEPTH (BOTTOM) ---\n",
    "    \n",
    "#     # Bottom depth check (using min elbow angle from the down phase)\n",
    "#     if bottom_elbow_angle is not None:\n",
    "#         # Relaxed threshold: Must be 110 degrees or less\n",
    "#         if bottom_elbow_angle > 110:\n",
    "#             issues.append(f\"Go deeper! (Min elbow angle {int(bottom_elbow_angle)}° > 110°)\")\n",
    "    \n",
    "#     # NOTE: Top lockout check removed due to instability from keypoint jitter.\n",
    "\n",
    "#     # --- 2. BODY LINE + HIP SAG / PIKE (Shoulder–Hip–Knee/Ankle) ---\n",
    "#     def check_body_side(side_prefixes):\n",
    "#         \"\"\"Returns the most critical body line issue, or None.\"\"\"\n",
    "#         s_key, h_key, k_key, a_key = side_prefixes\n",
    "        \n",
    "#         # Check if all required keys exist in KS\n",
    "#         if not all(key in KS for key in side_prefixes): return None\n",
    "        \n",
    "#         s_idx, h_idx, k_idx, a_idx = KS[s_key], KS[h_key], KS[k_key], KS[a_key]\n",
    "#         conf = kps[s_idx, 2] * kps[h_idx, 2] * kps[k_idx, 2]\n",
    "#         if conf <= 0.5: return None\n",
    "        \n",
    "#         shoulder = get_xy(kps, s_idx)\n",
    "#         hip      = get_xy(kps, h_idx)\n",
    "#         knee     = get_xy(kps, k_idx)\n",
    "#         ankle    = get_xy(kps, a_idx)\n",
    "        \n",
    "#         # Primary Check: S-H-A Angle\n",
    "#         body_angle = calculate_angle(shoulder, hip, ankle)\n",
    "#         if body_angle < 165:\n",
    "#             return f\"Keep body straighter (S-H-A angle {int(body_angle)}° < 165°)\"\n",
    "\n",
    "#         # Secondary Check: Sag/Pike offset (only if S-H-A angle passes)\n",
    "#         sh = np.array(shoulder)\n",
    "#         hp = np.array(hip)\n",
    "#         kn = np.array(knee)\n",
    "#         seg_len = np.linalg.norm(kn - sh)\n",
    "        \n",
    "#         if seg_len > 0:\n",
    "#             t = np.linalg.norm(hp - sh) / seg_len\n",
    "#             expected_hip_y = sh[1] + (kn[1] - sh[1]) * t\n",
    "#             hip_offset = hp[1] - expected_hip_y\n",
    "#             sag_thresh = 0.1 * seg_len # 10% of body segment as threshold\n",
    "            \n",
    "#             if hip_offset > sag_thresh:\n",
    "#                 return \"Hips sagging – tighten your core.\"\n",
    "#             elif hip_offset < -sag_thresh:\n",
    "#                 return \"Hips too high – avoid piking.\"\n",
    "                \n",
    "#         return None\n",
    "\n",
    "#     # Try left side first, then right\n",
    "#     body_issue = check_body_side(('ls', 'lh', 'lk', 'la'))\n",
    "#     if body_issue is None:\n",
    "#         body_issue = check_body_side(('rs', 'rh', 'rk', 'ra'))\n",
    "    \n",
    "#     if body_issue:\n",
    "#         issues.append(body_issue)\n",
    "    \n",
    "#     # Fallback to original simple check if full body points aren't available\n",
    "#     if not body_issue and kps[KS['ls'], 2] > 0.5 and kps[KS['lh'], 2] > 0.5 and kps[KS['lk'], 2] > 0.5:\n",
    "#          body_angle = calculate_angle(get_xy(kps, KS['ls']), get_xy(kps, KS['lh']), get_xy(kps, KS['lk']))\n",
    "#          if body_angle < 165:\n",
    "#               issues.append(f\"Fix hips! (Body angle {int(body_angle)}°, must be > 165°)\")\n",
    "            \n",
    "#     return issues\n",
    "\n",
    "import numpy as np\n",
    "# Assuming KS is defined elsewhere\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculates angle ABC (in degrees) where B is the vertex.\"\"\"\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    norm_ba = np.linalg.norm(ba)\n",
    "    norm_bc = np.linalg.norm(bc)\n",
    "    if norm_ba == 0 or norm_bc == 0:\n",
    "        return 180.0\n",
    "        \n",
    "    cosine_angle = np.dot(ba, bc) / (norm_ba * norm_bc)\n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def get_xy(kps, index):\n",
    "    \"\"\"Safe helper to get (x, y) tuple from keypoints.\"\"\"\n",
    "    return (float(kps[index, 0]), float(kps[index, 1]))\n",
    "\n",
    "def get_best_elbow_angle(kps):\n",
    "    \"\"\"\n",
    "    Returns the best elbow angle (left or right) based on confidence.\n",
    "    (Needed for min_elbow_angle tracking)\n",
    "    \"\"\"\n",
    "    if 'ls' not in KS or 'le' not in KS or 'lw' not in KS:\n",
    "        return None\n",
    "        \n",
    "    left_conf = kps[KS['ls'], 2] * kps[KS['le'], 2] * kps[KS['lw'], 2]\n",
    "    right_conf = kps[KS['rs'], 2] * kps[KS['re'], 2] * kps[KS['rw'], 2]\n",
    "    \n",
    "    elbow_angle = None\n",
    "    \n",
    "    if left_conf > right_conf and left_conf > 0.5:\n",
    "        elbow_angle = calculate_angle(\n",
    "            get_xy(kps, KS['ls']),\n",
    "            get_xy(kps, KS['le']),\n",
    "            get_xy(kps, KS['lw'])\n",
    "        )\n",
    "    elif right_conf > 0.5:\n",
    "        elbow_angle = calculate_angle(\n",
    "            get_xy(kps, KS['rs']),\n",
    "            get_xy(kps, KS['le']), # Fixed: was KS['re']\n",
    "            get_xy(kps, KS['rw'])\n",
    "        )\n",
    "    \n",
    "    return elbow_angle\n",
    "# REMOVED: assess_form_geometric (The AI Classifier replaces this logic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245281c",
   "metadata": {},
   "source": [
    "### 4. Live Webcam Loop\n",
    "This block runs the webcam, draws the skeleton, counts reps, and gives feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2810528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully. Using Robust Feature Engineering.\n",
      "Rep 1: Extend arms fully (No Lockout), Keep back straight! (Hip angle: 50°) (AI: incorrect, conf: 0.73)\n",
      "Rep 2: Go deeper! (Min angle: 156°), Extend arms fully (No Lockout), Keep back straight! (Hip angle: 99°) (AI: incorrect, conf: 0.91)\n",
      "Rep 3: Go deeper! (Min angle: 125°), Extend arms fully (No Lockout), Keep back straight! (Hip angle: 115°) (AI: incorrect, conf: 0.65)\n",
      "Rep 4: Extend arms fully (No Lockout), Keep back straight! (Hip angle: 125°) (AI: incorrect, conf: 0.57)\n",
      "Rep 5: Extend arms fully (No Lockout), Keep back straight! (Hip angle: 135°) (AI: incorrect, conf: 0.63)\n",
      "Rep 6: Go deeper! (Min angle: 152°), Extend arms fully (No Lockout) (AI: correct, conf: 0.53)\n",
      "Rep 7: Extend arms fully (No Lockout), Keep back straight! (Hip angle: 138°) (AI: incorrect, conf: 0.63)\n",
      "Rep 8: Extend arms fully (No Lockout), Keep back straight! (Hip angle: 131°) (AI: incorrect, conf: 0.57)\n",
      "Rep 9: Extend arms fully (No Lockout), Keep back straight! (Hip angle: 134°) (AI: incorrect, conf: 0.61)\n",
      "Rep 10: Go deeper! (Min angle: 150°), Extend arms fully (No Lockout), Keep back straight! (Hip angle: 107°) (AI: incorrect, conf: 0.58)\n",
      "Rep 11: Extend arms fully (No Lockout) (AI: correct, conf: 0.64)\n",
      "Rep 12: Go deeper! (Min angle: 146°), Extend arms fully (No Lockout), Keep back straight! (Hip angle: 99°) (AI: incorrect, conf: 0.85)\n",
      "Rep 13: Go deeper! (Min angle: 145°), Extend arms fully (No Lockout), Keep back straight! (Hip angle: 128°) (AI: incorrect, conf: 0.77)\n",
      "Rep 14: Extend arms fully (No Lockout), Keep back straight! (Hip angle: 82°) (AI: incorrect, conf: 0.69)\n",
      "Rep 15: Keep back straight! (Hip angle: 123°) (AI: incorrect, conf: 0.78)\n",
      "Rep 16: Go deeper! (Min angle: 160°), Extend arms fully (No Lockout), Keep back straight! (Hip angle: 83°) (AI: incorrect, conf: 0.82)\n",
      "Rep 17: Go deeper! (Min angle: 150°), Extend arms fully (No Lockout), Keep back straight! (Hip angle: 99°) (AI: incorrect, conf: 0.91)\n",
      "Rep 18: Extend arms fully (No Lockout) (AI: correct, conf: 0.53)\n",
      "Rep 19: Extend arms fully (No Lockout), Keep back straight! (Hip angle: 148°) (AI: incorrect, conf: 0.60)\n",
      "Rep 20: Keep back straight! (Hip angle: 145°) (AI: incorrect, conf: 0.72)\n",
      "Rep 21: Extend arms fully (No Lockout), Keep back straight! (Hip angle: 23°) (AI: incorrect, conf: 0.75)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import warnings\n",
    "from ultralytics import YOLO\n",
    "from math import sqrt\n",
    "# from sklearn.exceptions import UserWarning\n",
    "import os\n",
    "\n",
    "# --- SUPPRESS WARNINGS ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- 1. CONFIGURATION AND MODEL LOADING ---\n",
    "\n",
    "# Define Keypoint Structure\n",
    "KS = {\n",
    "    'nose': 0, 'le': 3, 're': 4, 'ls': 5, 'rs': 6, 'le': 7, 're': 8,\n",
    "    'lw': 9, 'rw': 10, 'lh': 11, 'rh': 12, 'lk': 13, 'rk': 14,\n",
    "    'la': 15, 'ra': 16\n",
    "}\n",
    "\n",
    "# Define body segments for drawing the skeleton\n",
    "SKELETON_LINES = [\n",
    "    (KS['ls'], KS['rs']), (KS['lh'], KS['rh']), (KS['ls'], KS['lh']), (KS['rs'], KS['rh']), \n",
    "    (KS['ls'], KS['le']), (KS['le'], KS['lw']),                                          \n",
    "    (KS['rs'], KS['re']), (KS['re'], KS['rw']),                                           \n",
    "    (KS['lh'], KS['lk']), (KS['lk'], KS['la']),                                          \n",
    "    (KS['rh'], KS['rk']), (KS['rk'], KS['ra'])                                            \n",
    "]\n",
    "\n",
    "\n",
    "# Exercise Parameters\n",
    "ELBOW_ANGLE_THRESHOLD = 125.0    \n",
    "HIP_ANGLE_THRESHOLD = 160.0     \n",
    "EXTENDED_ELBOW_THRESHOLD = 165.0 \n",
    "\n",
    "# >>> ADJUSTED FOR DISTANT WEBCAM START <<<\n",
    "RELATIVE_MOVE_THRESHOLD = 0.02   # Reduced from 0.05 to 0.02\n",
    "KP_CONF_MIN = 0.5                # Reduced from 0.8 to 0.5 (Fixes flickering skeleton)\n",
    "AI_CONF_MIN = 0.55               # Reduced from 0.65 (Optional, for noisier AI input)\n",
    "# >>> ADJUSTED FOR DISTANT WEBCAM END <<<\n",
    "\n",
    "POSE_MODEL_PATH = \"yolov8n-pose.pt\"\n",
    "CLASSIFIER_MODEL_PATH = \"pose_classifier_robust.pkl\" \n",
    "\n",
    "try:\n",
    "    pose_model = YOLO(POSE_MODEL_PATH)\n",
    "    rf_model = joblib.load(CLASSIFIER_MODEL_PATH)\n",
    "    print(\"Models loaded successfully. Using Robust Feature Engineering.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}. Ensure both files are in the directory and the model was re-trained as '{CLASSIFIER_MODEL_PATH}'.\")\n",
    "    pose_model = None\n",
    "    rf_model = None\n",
    "\n",
    "\n",
    "# --- 2. HELPER FUNCTIONS (No change needed here) ---\n",
    "\n",
    "def calculate_angle(kps, p1, p2, p3):\n",
    "    \"\"\"Calculates the angle (in degrees) between three keypoints, centered at p2.\"\"\"\n",
    "    p1_coords = kps[p1][:2]\n",
    "    p2_coords = kps[p2][:2]\n",
    "    p3_coords = kps[p3][:2]\n",
    "    \n",
    "    v1 = np.array(p1_coords) - np.array(p2_coords)\n",
    "    v2 = np.array(p3_coords) - np.array(p2_coords)\n",
    "    \n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    \n",
    "    if norm_v1 == 0 or norm_v2 == 0: return 180.0\n",
    "        \n",
    "    angle_rad = np.arccos(np.clip(dot_product / (norm_v1 * norm_v2), -1.0, 1.0))\n",
    "    return np.degrees(angle_rad)\n",
    "\n",
    "def get_best_elbow_angle(kps):\n",
    "    \"\"\"Returns the smallest elbow angle.\"\"\"\n",
    "    left_elbow_angle = calculate_angle(kps, KS['lw'], KS['le'], KS['ls'])\n",
    "    right_elbow_angle = calculate_angle(kps, KS['rw'], KS['re'], KS['rs'])\n",
    "    return min(left_elbow_angle, right_elbow_angle)\n",
    "\n",
    "def get_hip_angle(kps):\n",
    "    \"\"\"Calculates the angle for hip straightness (Shoulder-Hip-Knee).\"\"\"\n",
    "    left_angle = calculate_angle(kps, KS['ls'], KS['lh'], KS['lk'])\n",
    "    right_angle = calculate_angle(kps, KS['rs'], KS['rh'], KS['rk'])\n",
    "    return min(left_angle, right_angle)\n",
    "\n",
    "def create_robust_features(kps):\n",
    "    \"\"\"\n",
    "    Creates the same 20-feature vector used for training. \n",
    "    (8 Angles + 12 Ratios).\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    def dist(p1, p2): return np.linalg.norm(kps[p1, :2] - kps[p2, :2])\n",
    "\n",
    "    # 1. 8 Angles\n",
    "    features.append(calculate_angle(kps, KS['rw'], KS['re'], KS['rs']))\n",
    "    features.append(calculate_angle(kps, KS['lw'], KS['le'], KS['ls']))\n",
    "    features.append(calculate_angle(kps, KS['re'], KS['rs'], KS['rh']))\n",
    "    features.append(calculate_angle(kps, KS['le'], KS['ls'], KS['lh']))\n",
    "    features.append(calculate_angle(kps, KS['rs'], KS['rh'], KS['rk']))\n",
    "    features.append(calculate_angle(kps, KS['ls'], KS['lh'], KS['lk']))\n",
    "    features.append(calculate_angle(kps, KS['rh'], KS['rk'], KS['ra']))\n",
    "    features.append(calculate_angle(kps, KS['lh'], KS['lk'], KS['la']))\n",
    "\n",
    "    # 2. 12 Distance Ratios\n",
    "    torso_length = (dist(KS['ls'], KS['lh']) + dist(KS['rs'], KS['rh'])) / 2\n",
    "    if torso_length == 0: torso_length = 1.0\n",
    "\n",
    "    features.append(dist(KS['rs'], KS['re']) / torso_length) \n",
    "    features.append(dist(KS['re'], KS['rw']) / torso_length) \n",
    "    features.append(dist(KS['ls'], KS['le']) / torso_length) \n",
    "    features.append(dist(KS['le'], KS['lw']) / torso_length) \n",
    "    features.append(dist(KS['rs'], KS['ls']) / torso_length) \n",
    "    features.append(dist(KS['rh'], KS['lh']) / torso_length) \n",
    "    features.append(dist(KS['rh'], KS['rk']) / torso_length) \n",
    "    features.append(dist(KS['rk'], KS['ra']) / torso_length) \n",
    "    features.append(dist(KS['lh'], KS['lk']) / torso_length) \n",
    "    features.append(dist(KS['lk'], KS['la']) / torso_length) \n",
    "    features.append(dist(KS['nose'], KS['rs']) / torso_length) \n",
    "    features.append(dist(KS['nose'], KS['ls']) / torso_length) \n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# --- 3. LIVE LOOP STATE MACHINE ---\n",
    "\n",
    "if pose_model and rf_model:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # State variables\n",
    "    state = \"up\"\n",
    "    reps = 0\n",
    "    prev_y = None\n",
    "    min_elbow_angle = 180.0\n",
    "    feedback_buffer = None\n",
    "    default_color = (255, 255, 255) # White\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success: break\n",
    "\n",
    "        results = pose_model(frame, verbose=False)\n",
    "        \n",
    "        # Keypoint Extraction\n",
    "        kps = None\n",
    "        if results and results[0].keypoints.xyn.shape[0] > 0:\n",
    "            xy_normalized = results[0].keypoints.xyn[0].cpu().numpy()\n",
    "            conf_values = results[0].keypoints.conf[0].cpu().numpy().reshape(-1, 1)\n",
    "            kps_normalized_xyc = np.concatenate((xy_normalized, conf_values), axis=1)\n",
    "\n",
    "            scale_array = np.array([frame.shape[1], frame.shape[0], 1])\n",
    "            kps = kps_normalized_xyc * scale_array\n",
    "            \n",
    "        \n",
    "        conf_ok = False\n",
    "        skeleton_colors = {}\n",
    "        for line in SKELETON_LINES: skeleton_colors[line] = default_color\n",
    "            \n",
    "        if kps is not None:\n",
    "            # Note: We still check critical joints, but the KP_CONF_MIN is lower now\n",
    "            critical_joints = [KS['ls'], KS['rs'], KS['le'], KS['re'], KS['lh'], KS['rh']]\n",
    "            conf_ok = all(kps[j, 2] > KP_CONF_MIN for j in critical_joints)\n",
    "        \n",
    "        if kps is None or not conf_ok:\n",
    "            cv2.putText(frame, \"ADJUST CAMERA: Low Confidence/No Detection\", (20, 150), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 165, 255), 2)\n",
    "            prev_y = None\n",
    "            \n",
    "        else:\n",
    "            # --- Rep Counting Normalization ---\n",
    "            shoulder_y = (kps[KS['ls'], 1] + kps[KS['rs'], 1]) / 2\n",
    "            hip_y = (kps[KS['lh'], 1] + kps[KS['rh'], 1]) / 2\n",
    "            \n",
    "            shoulder_hip_distance = abs(shoulder_y - hip_y)\n",
    "            # The movement threshold is based on the shoulder-hip distance, which scales with distance\n",
    "            dynamic_move_threshold = shoulder_hip_distance * RELATIVE_MOVE_THRESHOLD \n",
    "            effective_move_threshold = max(5, dynamic_move_threshold) # Reduced minimum from 10 to 5\n",
    "\n",
    "            # --- State Tracking ---\n",
    "            if prev_y is not None:\n",
    "                delta_y = shoulder_y - prev_y\n",
    "                \n",
    "                # UP -> DOWN transition (Moving down = shoulder y increases)\n",
    "                if state == \"up\" and delta_y > effective_move_threshold:\n",
    "                    state = \"down\"\n",
    "                    min_elbow_angle = 180.0\n",
    "                    \n",
    "                # DOWN -> UP transition (Rep Completion: Moving up = shoulder y decreases)\n",
    "                elif state == \"down\" and delta_y < -effective_move_threshold:\n",
    "                    state = \"up\"\n",
    "                    \n",
    "                    # --- FINAL VERDICT EVALUATION ---\n",
    "                    reps += 1\n",
    "                    final_feedback = \"CORRECT FORM!\"\n",
    "                    feedback_color = (0, 255, 0) \n",
    "                    geo_issues = []\n",
    "                    \n",
    "                    current_min_angle = get_best_elbow_angle(kps)\n",
    "                    current_hip_angle = get_hip_angle(kps)\n",
    "                    \n",
    "                    # 1. Elbow Depth Check\n",
    "                    if min_elbow_angle > ELBOW_ANGLE_THRESHOLD:\n",
    "                        geo_issues.append(f\"Go deeper! (Min angle: {int(min_elbow_angle)}°)\")\n",
    "                    \n",
    "                    # 2. Full Extension Check\n",
    "                    if current_min_angle < EXTENDED_ELBOW_THRESHOLD:\n",
    "                        geo_issues.append(\"Extend arms fully (No Lockout)\")\n",
    "                        \n",
    "                    # 3. AI Classifier Check (for hip/back form)\n",
    "                    features = create_robust_features(kps) \n",
    "                    features_array = np.array(features).reshape(1, -1)\n",
    "                    \n",
    "                    ai_verdict_idx = rf_model.predict(features_array)[0]\n",
    "                    ai_proba = rf_model.predict_proba(features_array)[0]\n",
    "                    \n",
    "                    if ai_verdict_idx == 'correct':\n",
    "                        confidence = ai_proba[rf_model.classes_ == 'correct'][0]\n",
    "                    else:\n",
    "                        confidence = ai_proba[rf_model.classes_ == 'incorrect'][0]\n",
    "\n",
    "                    ai_feedback = f\" (AI: {ai_verdict_idx}, conf: {confidence:.2f})\"\n",
    "\n",
    "                    if ai_verdict_idx == 'incorrect' and confidence >= AI_CONF_MIN:\n",
    "                        if current_hip_angle < HIP_ANGLE_THRESHOLD:\n",
    "                             geo_issues.append(f\"Keep back straight! (Hip angle: {int(current_hip_angle)}°)\")\n",
    "                        else:\n",
    "                             geo_issues.append(\"Subtle Form Breakdown (AI flag)\")\n",
    "                            \n",
    "                    # Final Decision Logic\n",
    "                    if geo_issues:\n",
    "                        final_feedback = \", \".join(geo_issues)\n",
    "                        feedback_color = (0, 0, 255) # Red for any failure\n",
    "                        \n",
    "                        # Color the skeleton red if any issue is flagged\n",
    "                        for seg in SKELETON_LINES: skeleton_colors[seg] = (0, 0, 255) \n",
    "                        \n",
    "                        arm_segments = [(KS['ls'], KS['le']), (KS['le'], KS['lw']), (KS['rs'], KS['re']), (KS['re'], KS['rw'])]\n",
    "                        hip_segments = [(KS['ls'], KS['lh']), (KS['rs'], KS['rh']), (KS['lh'], KS['rh'])]\n",
    "                        \n",
    "                        if any(s in geo_issues for s in [\"Go deeper!\", \"Extend arms fully (No Lockout)\"]):\n",
    "                            for seg in arm_segments: skeleton_colors[seg] = (0, 0, 255)\n",
    "                        \n",
    "                        if any(s in geo_issues for s in [\"Keep back straight!\", \"Subtle Form Breakdown (AI flag)\"]):\n",
    "                            for seg in hip_segments: skeleton_colors[seg] = (0, 0, 255)\n",
    "                            \n",
    "                    else:\n",
    "                        for line in SKELETON_LINES: skeleton_colors[line] = (0, 255, 0) # Green for perfect form\n",
    "\n",
    "                    print(f\"Rep {reps}: {final_feedback}{ai_feedback}\")\n",
    "                    feedback_buffer = [final_feedback, feedback_color, time.time() + 3]\n",
    "                \n",
    "            # --- DYNAMIC FEEDBACK (DURING 'down' state) ---\n",
    "            if state == \"down\":\n",
    "                current_elbow_angle = get_best_elbow_angle(kps)\n",
    "                if current_elbow_angle < min_elbow_angle: min_elbow_angle = current_elbow_angle\n",
    "\n",
    "                # Dynamic Depth Warning (Orange for arms)\n",
    "                if current_elbow_angle > ELBOW_ANGLE_THRESHOLD + 10: \n",
    "                    feedback_buffer = [\"GO DEEPER!\", (0, 165, 255), time.time() + 0.5]\n",
    "                    arm_segments = [(KS['ls'], KS['le']), (KS['le'], KS['lw']), (KS['rs'], KS['re']), (KS['re'], KS['rw'])]\n",
    "                    for seg in arm_segments: skeleton_colors[seg] = (0, 165, 255)\n",
    "\n",
    "                # Dynamic Hip Warning (Red for torso/hips)\n",
    "                current_hip_angle = get_hip_angle(kps)\n",
    "                if current_hip_angle < HIP_ANGLE_THRESHOLD - 5:\n",
    "                    feedback_buffer = [\"WARNING: FIX HIPS/BACK NOW!\", (0, 0, 255), time.time() + 0.5]\n",
    "                    hip_segments = [(KS['ls'], KS['lh']), (KS['rs'], KS['rh']), (KS['lh'], KS['rh'])]\n",
    "                    for seg in hip_segments: skeleton_colors[seg] = (0, 0, 255)\n",
    "                    \n",
    "            prev_y = shoulder_y\n",
    "\n",
    "\n",
    "        # --- 4. DRAW SKELETON (UI) ---\n",
    "        if kps is not None and conf_ok:\n",
    "            for p1_idx, p2_idx in SKELETON_LINES:\n",
    "                p1, p2 = kps[p1_idx], kps[p2_idx]\n",
    "                segment_color = skeleton_colors.get((p1_idx, p2_idx), default_color)\n",
    "\n",
    "                if p1[2] > KP_CONF_MIN and p2[2] > KP_CONF_MIN: \n",
    "                    cv2.line(frame, (int(p1[0]), int(p1[1])), (int(p2[0]), int(p2[1])), \n",
    "                             segment_color, 2)\n",
    "            \n",
    "            for i in range(kps.shape[0]):\n",
    "                kp = kps[i]\n",
    "                if kp[2] > KP_CONF_MIN:\n",
    "                    cv2.circle(frame, (int(kp[0]), int(kp[1])), 5, default_color, -1) \n",
    "\n",
    "        # --- 5. Draw Text UI ---\n",
    "        cv2.putText(frame, f\"Reps: {reps}\", (20, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "        \n",
    "        cv2.putText(frame, f\"State: {state.upper()}\", (20, 100),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        if feedback_buffer and time.time() < feedback_buffer[2]:\n",
    "            text, color, _ = feedback_buffer\n",
    "            cv2.putText(frame, text, (20, 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Pushup Trainer\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "    # cleanup\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "else:\n",
    "    print(\"Cannot run live loop due to model loading error.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
